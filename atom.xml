<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>imchengliang</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-07-11T11:36:34.735Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Cheng Liang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Singular Value Decomposition (SVD) Part 2</title>
    <link href="http://example.com/2022/07/08/SVD2/"/>
    <id>http://example.com/2022/07/08/SVD2/</id>
    <published>2022-07-08T09:00:21.000Z</published>
    <updated>2022-07-11T11:36:34.735Z</updated>
    
    <content type="html"><![CDATA[<p>In <a href="https://imchengliang.top/2022/01/14/post-1/">Singular Value Decomposition (SVD) Part 1</a>, I introduce one way to calculate SVD. And in this post, I would talk about other ideas about solving SVD.</p><h2 id="matrix-a-is-symmetric">Matrix <span class="math inline">\(A\)</span> is symmetric</h2><p><span class="math display">\[\begin{aligned}A \cdot\left(q_{1}, \ldots q_{n}\right)&amp;=\left(\lambda_{1} q_{1} \ldots \lambda_{n} q_{n}\right) \\&amp;=\left(\begin{array}{lll}q_{1} &amp; \cdots &amp; q_{n}\end{array}\right) \cdot\left(\begin{array}{ccc}\lambda_{1} &amp; \cdots &amp; \cdots \\ \vdots &amp; \ddots &amp; \vdots \\ \cdots &amp; \lambda_{n} &amp; \cdots\end{array}\right)\end{aligned}\]</span> When the matrix <span class="math inline">\(A\)</span> is symmetric, the eigenvectors <span class="math inline">\(Q\)</span> of <span class="math inline">\(A\)</span> would be orthogonal. And <span class="math inline">\(Q^{-1} = Q^{\top}\)</span> for orthogonal matrix. Then we get the SVD as below: <span class="math display">\[\begin{aligned}AQ=Q \lambda  \quad \rightarrow  \quad A=Q \lambda Q^{-1}=Q \lambda Q^{\top}\end{aligned}\]</span></p><h2 id="matrix-a-isnt-symmetric">Matrix <span class="math inline">\(A\)</span> isn't symmetric</h2><p>In big data world, <span class="math inline">\(A\)</span> is a data matrix but it's not always a square matrix. Under this situation, we can't work directly with the eigenvectors of <span class="math inline">\(A\)</span>, <span class="math inline">\(A^{\top}A\)</span> and <span class="math inline">\(AA^{\top}\)</span> are required for SVD. Then we get "sort of" <span class="math inline">\(\lambda ^{2}\)</span>, which are two sets of eigenvectors:</p><ol type="1"><li><p>n right singular vectors, <span class="math inline">\(v_{1}, \cdots , v_{n}\)</span> orthogonal in <span class="math inline">\(R^n\)</span></p></li><li><p>m left singular vectors, <span class="math inline">\(u_{1}, \cdots , u_{n}\)</span> orthogonal in <span class="math inline">\(R^m\)</span></p></li></ol><p>If <span class="math inline">\(A=U \Sigma V^{\top}\)</span>, then <span class="math inline">\(A^{\top} A=\left(U \Sigma V^{\top}\right)^{\top}\left(U \Sigma V^{\top}\right)=V^{\top} \Sigma^{\top} U^{\top} U \Sigma V^{\top}=V \Sigma^{\top} \Sigma V^{\top} \rightarrow n \times n\)</span></p><p><span class="math inline">\(\Sigma^{\top} \Sigma=\left(\begin{array}{llll} \sigma_{1} &amp; &amp; \\ &amp; \ddots &amp; \\ &amp; &amp; \sigma_{n} \end{array}\right)\left(\begin{array}{lll} \sigma_{1} &amp; &amp; \\ &amp; \ddots &amp; \\ &amp; &amp; \sigma_{n} \end{array}\right)=\left(\begin{array}{lll} \sigma_{1}^{2} &amp; &amp; \\ &amp; \ddots &amp; \\ &amp; &amp; \sigma_{n}^{2} \end{array}\right)\)</span></p><p><span class="math inline">\(\rightarrow\left(\sigma_{1}{ }^{2} \cdots \sigma_{n}{ }^{2}\right)\)</span> are eigenvalues of <span class="math inline">\(A^{\top} A\)</span></p><p><span class="math inline">\(A A^{\top}=\left(U \Sigma V^{\top}\right)\left(U \Sigma V^{\top}\right)^{\top}=U \Sigma V^{\top} V^{\top} \Sigma^{\top} U^{\top}=U \Sigma \Sigma^{\top} U^{\top} \rightarrow m \times m\)</span></p><p><span class="math inline">\(\Sigma \Sigma^{\top}=\left(\begin{array}{llll} \sigma_{1} &amp; &amp; \\ &amp; \ddots &amp; \\ &amp; &amp; \sigma_{m} \end{array}\right)\left(\begin{array}{lll} \sigma_{1} &amp; &amp; \\ &amp; \ddots &amp; \\ &amp; &amp; \sigma_{m} \end{array}\right)=\left(\begin{array}{lll} \sigma_{1}^{2} &amp; &amp; \\ &amp; \ddots &amp; \\ &amp; &amp; \sigma_{m}^{2} \end{array}\right)\)</span></p><p><span class="math inline">\(\rightarrow\left(\sigma_{1}^{2} \cdots \sigma_{m}^{2}\right)\)</span> are eigenvalues of <span class="math inline">\(A A^{\top}\)</span></p><p>Then in <span class="math inline">\(A=U \Sigma V^{\top}\)</span>, <span class="math inline">\(V\)</span> is the eigenvector of <span class="math inline">\(A^{\top}A\)</span>, <span class="math inline">\(U\)</span> is the eigenvectors of <span class="math inline">\(AA^{\top}\)</span>, the diagonal elements in <span class="math inline">\(\Sigma\)</span> are the root of the first same n non-zero eigenvalues of <span class="math inline">\(A^{\top}A\)</span> and <span class="math inline">\(AA^{\top}\)</span>.</p><h2 id="example">Example</h2><p><span class="math inline">\(A=\left(\begin{array}{ll} 1 &amp; 0 \\ 4 &amp; 6 \\ 0 &amp; 1 \end{array}\right) \quad, \quad A^{\top} A=\left(\begin{array}{ll} 17 &amp; 24 \\ 24 &amp; 37 \end{array}\right) \quad, \quad A A^{\top}=\left(\begin{array}{ccc}1 &amp; 4 &amp; 0 \\ 4 &amp; 52 &amp; 6 \\ 0 &amp; 6 &amp; 1\end{array}\right)\)</span></p><p>For <span class="math inline">\(A^{\top} A\)</span></p><p>Eigenvalues: <span class="math inline">\(\lambda_{1}=53, \lambda_{2}=1\)</span></p><p>Eigenvectors: <span class="math inline">\(v_{1}=\left(\begin{array}{l}0.55 \\ 0.83\end{array}\right), \quad v_{2}=\left(\begin{array}{c}-0.83 \\ 0.55\end{array}\right)\)</span></p><p><span class="math inline">\(A^{\top} A \cdot\left(\begin{array}{cc}0.55 &amp; -0.83 \\ 0.83 &amp; 0.55\end{array}\right)=\left(\begin{array}{cc}0.55 &amp; -0.83 \\ 0.83 &amp; 0.55\end{array}\right) \cdot\left(\begin{array}{cc}53 &amp; 0 \\ 0 &amp; 1\end{array}\right)\)</span></p><p>For <span class="math inline">\(A A^{\top}\)</span></p><p>Eigenvalues: <span class="math inline">\(\lambda_{1}=53, \lambda_{2}=1, \lambda_{3}=0\)</span></p><p>Eigenvectors: <span class="math inline">\(u_{1}=\left(\begin{array}{l}0.08 \\ 0.99 \\ 0.11\end{array}\right), \quad u_{2}=\left(\begin{array}{c}-0.83 \\ 0 \\ 0.56\end{array}\right), \quad u_{3}=\left(\begin{array}{c}-0.55 \\ 0.14 \\ -0.82\end{array}\right)\)</span></p><p>Order the same eigenvalues of <span class="math inline">\(A^{\top}A\)</span> and <span class="math inline">\(AA^{\top}\)</span> from large to small: <span class="math inline">\(\sigma_{1}=\sqrt{53}, \quad \sigma_{2}=1\)</span></p><p><span class="math inline">\(A=U \Sigma V^{\top}=\left(\begin{array}{ccc} 0.08 &amp; -0.83 &amp; -0.55 \\ 0.99 &amp; 0 &amp; 0.14 \\ 0.11 &amp; 0.56 &amp; -0.82 \end{array}\right) \cdot\left(\begin{array}{cc} \sqrt{53} &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 0 \end{array}\right) \cdot\left(\begin{array}{cc} 0.55 &amp; 0.83 \\ -0.83 &amp; 0.35 \end{array}\right)\)</span></p><h2 id="svd-in-python">SVD in Python</h2><p>We can use numpy to construct a matrix in Python. The module linalg in numpy offers many functions of matrix operation</p><figure class="highlight oxygene"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs oxygene">import numpy <span class="hljs-keyword">as</span> np<br>A = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">0</span>]])<br># <span class="hljs-function"><span class="hljs-keyword">Method</span> 1:</span> use svd <span class="hljs-function"><span class="hljs-keyword">function</span></span><br><span class="hljs-function"># <span class="hljs-title">VT</span> <span class="hljs-title">is</span> <span class="hljs-title">the</span> <span class="hljs-title">Transpose</span> <span class="hljs-title">of</span> <span class="hljs-title">V</span>, <span class="hljs-title">if</span> <span class="hljs-title">we</span> <span class="hljs-title">want</span> <span class="hljs-title">the</span> <span class="hljs-title">matrix</span> <span class="hljs-title">V</span>, <span class="hljs-title">use</span> <span class="hljs-title">VT</span>.<span class="hljs-title">T</span></span><br><span class="hljs-function"><span class="hljs-title">U</span>, <span class="hljs-title">Sigma</span>, <span class="hljs-title">VT</span> = <span class="hljs-title">np</span>.<span class="hljs-title">linalg</span>.<span class="hljs-title">svd</span><span class="hljs-params">(A, full_matrices=<span class="hljs-keyword">True</span>)</span></span><br><span class="hljs-function"># <span class="hljs-title">Method</span> 2:</span> find svd through eigenvectors <span class="hljs-keyword">and</span> eigenvalues<br>ATA = np.dot(A.T, A)<br>eig1 = np.linalg.eig(ATA)<br>AAT = np.dot(A, A.T)<br>eig2 = np.linalg.eig(AAT)<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In &lt;a href=&quot;https://imchengliang.top/2022/01/14/post-1/&quot;&gt;Singular Value Decomposition (SVD) Part 1&lt;/a&gt;, I introduce one way to calculate </summary>
      
    
    
    
    <category term="Mathematics" scheme="http://example.com/categories/Mathematics/"/>
    
    
    <category term="Linear Algebra" scheme="http://example.com/tags/Linear-Algebra/"/>
    
  </entry>
  
  <entry>
    <title>Tensor Operation</title>
    <link href="http://example.com/2022/07/06/Tensor-operation/"/>
    <id>http://example.com/2022/07/06/Tensor-operation/</id>
    <published>2022-07-06T09:50:08.000Z</published>
    <updated>2022-07-07T15:38:29.538Z</updated>
    
    <content type="html"><![CDATA[<p>In machine learning/big data we can think of a tensor as an nD-array. The picture below is an example of a rank 3 tensor with size (3,4,2). <img src="https://cdn.mathpix.com/snip/images/Ti2SGPSC9LcV-zTuwcDBZ1hNsc58kzPE94fa5oCWhrE.original.fullsize.png"></p><h2 id="tensor-unfolding">Tensor unfolding</h2><p>Unfolding a tensor to a matrix (“matrization”) is a fundamental operation for most tensor methods and we can do it in different ways (use the tensor above as example).</p><p>Mode-1 unfolding: The column vectors of <span class="math inline">\(a_n\)</span> are column vectors of <span class="math inline">\(A_1\)</span> <span class="math display">\[A_{1}=\left(\begin{array}{cccccccc}0 &amp; 2 &amp; 4 &amp; 6 &amp; 1 &amp; 3 &amp; 5 &amp; 7 \\8 &amp; 10 &amp; 12 &amp; 14 &amp; 9 &amp; 11 &amp; 13 &amp; 15 \\16 &amp; 18 &amp; 20 &amp; 22 &amp; 17 &amp; 19 &amp; 21 &amp; 23\end{array}\right)\]</span></p><p>Mode-2 unfolding: The row vectors of <span class="math inline">\(a_n\)</span> are column vectors of <span class="math inline">\(A_2\)</span> <span class="math display">\[A_{2}=\left(\begin{array}{cccccc}0 &amp; 8 &amp; 16 &amp; 1 &amp; 9 &amp; 17 \\ 2 &amp; 10 &amp; 18 &amp; 3 &amp; 11 &amp; 19 \\ 4 &amp; 12 &amp; 20 &amp; 5 &amp; 13 &amp; 21 \\ 6 &amp; 14 &amp; 22 &amp; 7 &amp; 15 &amp; 23\end{array}\right)\]</span></p><p>Mode-3 unfolding: The mode-3 vectors of <span class="math inline">\(a_n\)</span> are columns vectors of <span class="math inline">\(A_3\)</span> <span class="math display">\[A_{3}=\left(\begin{array}{llllllllllll}0 &amp; 2 &amp; 4 &amp; 6 &amp; 8 &amp; 10 &amp; 12 &amp; 14 &amp; 16 &amp; 18 &amp; 20 &amp; 22 \\ 1 &amp; 3 &amp; 5 &amp; 7 &amp; 9 &amp; 11 &amp; 13 &amp; 15 &amp; 17 &amp; 19 &amp; 21 &amp; 23\end{array}\right)\]</span></p><h2 id="tensor-matrix-multiplication">Tensor-matrix multiplication</h2><p>1-mode multiplication: <span class="math inline">\(U \cdot a_n\)</span> (<span class="math inline">\(U\)</span> is the matrix that we need to multiply, and <span class="math inline">\(a_n\)</span> is the tensor we use)</p><ol type="1"><li><p>Mode-1 unfolding the tensor <span class="math inline">\(a_n \rightarrow A_1\)</span></p></li><li><p>Matrix-matrix multiplication <span class="math inline">\(U \cdot A_{1} = Y_{1}\)</span></p></li><li><p>Refold (fold the matrix back to a tensor) <span class="math inline">\(Y_{1} \rightarrow y_{1}\)</span></p></li></ol><p>Same principle for mode-2 multiplication and mode-3 multiplication etc.</p><h2 id="outer-product">Outer product</h2><p>Outer product between two vectors <span class="math inline">\(a^{1}, a^{2}\)</span> is <span class="math inline">\(a^{1} \cdot a^{2^{\top}}\)</span>, which is a 2D-matrix of rank=1 .</p><p>Outer product between three vectors <span class="math inline">\(a^{1}, a^{2}, a^{3}\)</span> is a tensor <span class="math inline">\(a_n\)</span> with three slices, and each slice is of rank=1. Each element in the tensor: <span class="math inline">\(a_n(i,j,k)\)</span> is defined by <span class="math inline">\({a^{1}}_{i} \cdot {a^{2}}_{j} \cdot {a^{3}}_{k}\)</span> (<span class="math inline">\(i\)</span> means i-th slice, <span class="math inline">\(j\)</span> means j-th row, <span class="math inline">\(k\)</span> means k-th column).</p><p>Frontal slices: in a <span class="math inline">\(3*3*3\)</span> tensor, the frontal slices is tensor[n, n, n], and n can be :, 0, 1, 2. : means choose all, 0 means to choose the first one, 1 means to choose the second one, and 2 means to choose the third one. The first n represents slice, the second n represents row, and the last n represents column.</p><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># Outer product</span><br><span class="hljs-attribute">import</span> numpy as np<br><span class="hljs-attribute">a1</span> = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>])<br><span class="hljs-attribute">a2</span> = np.array([<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>])<br><span class="hljs-attribute">a3</span> = np.array([<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>])<br><span class="hljs-attribute">t1</span> = np.outer(np.outer(a<span class="hljs-number">1</span>,a<span class="hljs-number">2</span>),a<span class="hljs-number">3</span>)<br><span class="hljs-attribute">t2</span> = t<span class="hljs-number">1</span>.reshape(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>)<br><span class="hljs-comment"># Frontal slices</span><br><span class="hljs-attribute">t2</span>[:,:,<span class="hljs-number">0</span>] # first column of each slice<br><span class="hljs-attribute">t2</span>[<span class="hljs-number">0</span>,:,:] # first slice<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In machine learning/big data we can think of a tensor as an nD-array. The picture below is an example of a rank 3 tensor with size (3,4,2</summary>
      
    
    
    
    
    <category term="Linear Algebra" scheme="http://example.com/tags/Linear-Algebra/"/>
    
  </entry>
  
  <entry>
    <title>QR Decomposition</title>
    <link href="http://example.com/2022/06/28/QR2/"/>
    <id>http://example.com/2022/06/28/QR2/</id>
    <published>2022-06-28T12:50:21.000Z</published>
    <updated>2022-07-06T09:42:12.662Z</updated>
    
    <content type="html"><![CDATA[<p>The QR (orthogonal triangular) decomposition is the most effective and widely used method to find all the eigenvalues of a general matrix. It decomposes the matrix into a normal orthogonal matrix <span class="math inline">\(Q\)</span> and an upper triangular matrix <span class="math inline">\(R\)</span>, so it is called the QR decomposition. There are two common methods of QR decomposition, one is based on Gram-Schmidt, and the other one is based on Householder reflectors.</p><h2 id="qr-decomposition-based-on-gram-schmidt">QR decomposition based on Gram-Schmidt</h2><p>Let say a matrix <span class="math inline">\(A=(a_{1} \quad a_{2} \quad a_{3})\)</span> for example, then <span class="math inline">\(Ax=(a_{1} \quad a_{2} \quad a_{3})x=b\)</span>. To find the <span class="math inline">\(Q\)</span> and <span class="math inline">\(R\)</span> for <span class="math inline">\(A\)</span>, we need to orthogonalize and normalize every vector in <span class="math inline">\(A\)</span> (* for the first vector <span class="math inline">\(a_1\)</span>, only normalization is required).</p><ol type="1"><li><p>Normalize <span class="math inline">\(a_1\)</span>: <span class="math inline">\(\quad g_{1}=\frac{a_{1}}{\parallel a_{1} \parallel}, \quad a_{1}=\left\|a_{1}\right\| g_{1}\)</span></p></li><li><p>Orthogonalize <span class="math inline">\(a_2\)</span>: <span class="math inline">\(\quad a_{2}^{\prime}=a_{2}-(a_{2}^{\top}g_{1})g_{1}\)</span></p></li><li><p>Normalize <span class="math inline">\(a_2\)</span>: <span class="math inline">\(\quad g_{2}=\frac{a_{2}^{\prime}}{\left\|a_{2}^{\prime}\right\|}, \quad a_{2}=\left(a_{2}^{\top} g_{1}\right) g_{1}+\left\|a_{2}^{\prime}\right\| g_{2}\)</span></p></li><li><p>Orthogonalise <span class="math inline">\(a_{3}\)</span>: <span class="math inline">\(\quad a_{3}^{\prime}=a_{3}-\left(a_{3}^{\top} g_{1}\right) g_{1}-\left(a_{3}^{\top} g_{2}\right) g_{2}\)</span></p></li><li><p>Normalize <span class="math inline">\(a_{3}\)</span>: <span class="math inline">\(\quad g_{3}=\frac{a_{3}{ }^{\prime}}{\left\|a_{3}\right\|}, \quad a_{3}=\left(a_{3}^{\top} g_{1}\right) g_{1}+\left(a_{3}^{\top} g_{2}\right) g_{2}+\left\|a_{3}^{\prime}\right\| g_{3}\)</span></p></li></ol><p>After the orthogonalization and normalization, we get <span class="math inline">\(Q=\left(\begin{array}{lll} g_{1} &amp; g_{2} &amp; g_{3} \end{array}\right)\)</span> and <span class="math inline">\(R=\left(\begin{array}{ccc} \left\|a_{1}\right\| &amp; a_{2}^{\top} g_{1} &amp; a_{3}^{\top} g_{1} \\ 0 &amp; \left\|a_{2}\right\| &amp; a_{3}^{\top} g_{2} \\ 0 &amp; 0 &amp; \left\|a_{3}\right\| \end{array}\right)\)</span></p><p>One problem with Gram-Schmidt is that <span class="math inline">\(g_{1}, g_{2}, g_{3}\)</span> won't be exactly orthogonal due to error in the computations (round-off).</p><p>And as <span class="math inline">\(g_3\)</span> depends on <span class="math inline">\(g_1\)</span> and <span class="math inline">\(g_2\)</span>, the problem tends to get worse and worse. The vectors get less and less orthogonal in practice. Therefore, it's better to use Householder reflectors when we apply QR decomposition.</p><h2 id="qr-decomposition-based-on-householder-reflectors">QR decomposition based on Householder reflectors</h2><p>Householder reflector: <span class="math inline">\(H=I-2uu^{\top}=I-\frac{2 v v^{\top}}{\|v\|_{2}{ }^{2}}, \quad H^{2}=I\)</span></p><p>For every reflector, it is orthogonal and doesn't change length <span class="math inline">\(\rightarrow H^{2}=H^{\top}H=I\)</span></p><p>Now consider <span class="math inline">\(A\)</span> as a <span class="math inline">\(4*3\)</span> matrix for example, then <span class="math inline">\(Q_{n}\)</span> <span class="math inline">\((n=1,2,3)\)</span>, all are square matrix with size of <span class="math inline">\(4*4\)</span>. We can find <span class="math inline">\(Q_{n}\)</span> one by one following the steps below.</p><p>Find <span class="math inline">\(Q_1\)</span> that makes <span class="math inline">\(Q_{1}A=\left(\begin{array}{ccc}x &amp; x &amp; x \\ 0 &amp; x &amp; x \\ 0 &amp; x &amp; x \\ 0 &amp; x &amp; x\end{array}\right)\)</span>:</p><p><span class="math inline">\(\quad v=a_{1}+\left\|a_{1}\right\|e_{1} \quad\)</span> (<span class="math inline">\(a_{1}\)</span> is the first column in <span class="math inline">\(A\)</span>), <span class="math inline">\(\quad Q_{1}=I - \frac{2 v v^{\top}}{\|v\|_{2}{ }^{2}}\)</span></p><p>Find <span class="math inline">\(Q_2\)</span> that makes <span class="math inline">\(Q_{2}(Q_{1}A)=\left(\begin{array}{ccc}x &amp; x &amp; x \\ 0 &amp; x &amp; x \\ 0 &amp; 0 &amp; x \\ 0 &amp; 0 &amp; x\end{array}\right)\)</span>:</p><p><span class="math inline">\(\quad v=a_{2}+\left\|a_{2}\right\|e_{1} \quad\)</span> (<span class="math inline">\(a_{2}\)</span> is last three elements of the second column in <span class="math inline">\(Q_{1}A\)</span>)</p><p><span class="math inline">\(\quad Q_{2}^{\prime}=I - \frac{2 v v^{\top}}{\|v\|_{2}{ }^{2}}\)</span>, <span class="math inline">\(\quad Q_{2}=\left(\begin{array}{cccc}1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; Q_{2_{1,1}}^{\prime} &amp; Q_{2_{1,2}}^{\prime} &amp; Q_{2_{1,3}}^{\prime} \\ 0 &amp; Q_{2_{2,1}}^{\prime} &amp; Q_{2_{2,2}}^{\prime} &amp; Q_{2_{2,3}}^{\prime} \\ 0 &amp; Q_{2_{3,1}}^{\prime} &amp; Q_{2_{3,2}}^{\prime} &amp; Q_{2_{3,3}}^{\prime} \end{array}\right)\)</span></p><p>Find <span class="math inline">\(Q_3\)</span> that makes <span class="math inline">\(Q_{3}(Q_{2}Q_{1}A)=\left(\begin{array}{ccc}x &amp; x &amp; x \\ 0 &amp; x &amp; x \\ 0 &amp; 0 &amp; x \\ 0 &amp; 0 &amp; 0\end{array}\right)\)</span>:</p><p><span class="math inline">\(\quad v=a_{3}+\left\|a_{3}\right\|e_{1} \quad\)</span> (<span class="math inline">\(a_{3}\)</span> is last two elements of the third column in <span class="math inline">\(Q_{2}(Q_{1}A)\)</span>)</p><p><span class="math inline">\(\quad Q_{3}^{\prime}=I - \frac{2 v v^{\top}}{\|v\|_{2}{ }^{2}}\)</span>, <span class="math inline">\(\quad Q_{3}=\left(\begin{array}{cccc}1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; Q_{3_{1,1}}^{\prime} &amp; Q_{3_{1,2}}^{\prime} \\ 0 &amp; 0 &amp; Q_{3_{2,1}}^{\prime} &amp; Q_{3_{2,2}}^{\prime} \end{array}\right)\)</span></p><p><span class="math inline">\(Q_{3} Q_{2} Q_{1} A=R \rightarrow A=Q_{1}^{\top} Q_{2}^{\top} Q_{3}^{\top} R=Q R\)</span>, and we get <span class="math inline">\(Q=Q_{1}^{\top} Q_{2}^{\top} Q_{3}^{\top}\)</span></p><h2 id="qr-decomposition-in-python">QR Decomposition in Python</h2><figure class="highlight maxima"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs maxima">import math<br>import argparse<br>import numpy as <span class="hljs-built_in">np</span><br>from typing import Union<br><br># QR decomposition based on Gram-Schmidt<br>def gram_schmidt(A):<br>    cols = A.shape[<span class="hljs-number">1</span>]<br>    Q = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">copy</span>(A)<br>    R = <span class="hljs-built_in">np</span>.zeros((cols, cols))<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">col</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cols):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">col</span>):<br>            k =  <span class="hljs-built_in">np</span>.<span class="hljs-built_in">sum</span>(a[:, <span class="hljs-built_in">col</span>] * Q[:, i]) / <span class="hljs-built_in">np</span>.<span class="hljs-built_in">sum</span>( <span class="hljs-built_in">np</span>.square(Q[:, i]) )<br>            Q[:, <span class="hljs-built_in">col</span>] -= k*Q[:, i]<br>        Q[:, <span class="hljs-built_in">col</span>] /= <span class="hljs-built_in">np</span>.linalg.norm(Q[:, <span class="hljs-built_in">col</span>])<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cols):<br>            R[<span class="hljs-built_in">col</span>, i] = Q[:, <span class="hljs-built_in">col</span>].dot( A[:, i] )   <br>    <span class="hljs-built_in">return</span> Q, R  <br><br># QR decomposition based on Householder reflectors  <br>def householder(alpha: <span class="hljs-built_in">float</span>, x: <span class="hljs-built_in">np</span>.ndarray) -&gt; Union[<span class="hljs-built_in">np</span>.ndarray, int]:<br>    s = math.pow(<span class="hljs-built_in">np</span>.linalg.norm(x, ord=<span class="hljs-number">2</span>), <span class="hljs-number">2</span>)<br>    v = x<br>    <span class="hljs-keyword">if</span> s == <span class="hljs-number">0</span>:<br>        tau = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">else</span>:<br>        t = math.<span class="hljs-built_in">sqrt</span>(alpha * alpha + s)<br>        v_one = alpha - t <span class="hljs-keyword">if</span> alpha &lt;= <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> -s / (alpha + t)<br>        tau = <span class="hljs-number">2</span> * v_one * v_one / (s + v_one * v_one)<br>        v /= v_one<br>    <span class="hljs-built_in">return</span> v, tau<br><br>def qr_decomposition(A: <span class="hljs-built_in">np</span>.ndarray, m: int, n: int) -&gt; Union[<span class="hljs-built_in">np</span>.ndarray, <span class="hljs-built_in">np</span>.ndarray]:<br>    H = []<br>    R = A<br>    Q = A<br>    I = <span class="hljs-built_in">np</span>.eye(m, m)<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, n):<br>        # Apply Householder transformation.<br>        x = A[j + <span class="hljs-number">1</span>:m, j]<br>        v_householder, tau = householder(<span class="hljs-built_in">np</span>.linalg.norm(x), x)<br>        v = <span class="hljs-built_in">np</span>.zeros((<span class="hljs-number">1</span>, m))<br>        v[<span class="hljs-number">0</span>, j] = <span class="hljs-number">1</span><br>        v[<span class="hljs-number">0</span>, j + <span class="hljs-number">1</span>:m] = v_householder<br>        res = I - tau * v * <span class="hljs-built_in">np</span>.<span class="hljs-built_in">transpose</span>(v)<br>        R = <span class="hljs-built_in">np</span>.matmul(res, R)<br>        H.<span class="hljs-built_in">append</span>(res)<br>    <span class="hljs-built_in">return</span> Q, R<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The QR (orthogonal triangular) decomposition is the most effective and widely used method to find all the eigenvalues of a general matrix</summary>
      
    
    
    
    <category term="Mathematics" scheme="http://example.com/categories/Mathematics/"/>
    
    
    <category term="Linear Algebra" scheme="http://example.com/tags/Linear-Algebra/"/>
    
  </entry>
  
  <entry>
    <title>The Least Squares Problem</title>
    <link href="http://example.com/2022/04/16/QR-decomposition/"/>
    <id>http://example.com/2022/04/16/QR-decomposition/</id>
    <published>2022-04-15T22:02:08.000Z</published>
    <updated>2022-07-06T09:40:58.938Z</updated>
    
    <content type="html"><![CDATA[<p>The Least Squares Problem is one of the most important problem in numerical approximation. The main idea of the least squares problem is to solve the unknown parameters , so that the sum of the squares of the difference between the predicted value and the observed value (i.e. the error, or residual) is minimized. In short, it can be interpreted as solving the equation of <span class="math inline">\(Ax=b\)</span>. In linear algebra, there are three common ways to solve the least squares problem, and their introduction and comparison are shown as below.</p><h2 id="the-normal-equations">The normal equations</h2><p>For an overdetermined systems (<span class="math inline">\(m*n\)</span>): <span class="math inline">\(Ax=b\)</span> such as: <span class="math display">\[\left(\begin{array}{ll}1 &amp; 4 \\1 &amp; 2 \\1 &amp; 3\end{array}\right)\left(\begin{array}{l}x_{1} \\x_{2}\end{array}\right)=\left(\begin{array}{l}3 \\3 \\2\end{array}\right) \Leftrightarrow\left(\begin{array}{l}1 \\1 \\1\end{array}\right) x_{1}+\left(\begin{array}{l}4 \\2 \\3\end{array}\right) x_{2}=\left(\begin{array}{l}3 \\3 \\2\end{array}\right)\]</span> We can't solve the system by <span class="math inline">\(a_{1}x_{1}+a_{2}x_{2}=b\)</span> because we can't reach <span class="math inline">\(b\)</span> through a linear combination of <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_2\)</span>. This method only works when <span class="math inline">\(b \in C(A)\)</span> (It's very unlikely when <span class="math inline">\(m&gt;n\)</span>).</p><p>Therefore, we find the vector <span class="math inline">\(p\)</span> closest to <span class="math inline">\(b\)</span> in the same plane of <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_2\)</span>, and let <span class="math inline">\(e=b-p\)</span> to be as small as possible and orthogonal to <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_2\)</span> (<span class="math inline">\(C(A)\)</span>).</p><p>Then find a solution <span class="math inline">\(\hat{x}\)</span> such that <span class="math inline">\(p=a_{1}\hat{x}_{1}+a_{2}\hat{x}_{2}\)</span>, and <span class="math inline">\(p\)</span> is the projection of <span class="math inline">\(b\)</span> onto <span class="math inline">\(C(A)\)</span>. <span class="math display">\[\begin{aligned}&amp;p=a_{1} \hat{x}_{1}+a_{2} \hat{x}_{2}=A \hat{x} \\&amp;e=b-p=b-A \hat{x} \\\end{aligned}\]</span> Orthogonality yield <span class="math display">\[\begin{aligned}&amp;\left\{\begin{array}{l}a_{1} \perp e \Leftrightarrow a_{1}^{T} e=0 \\a_{2} \perp e \Leftrightarrow a_{2}^{T} e=0\end{array} \Leftrightarrow A^{T} e=0 \Leftrightarrow A^{T}(b-A \hat{x})=0\right.\end{aligned}\]</span></p><p>The normal equations is <span class="math inline">\(A^{T}A\hat{x}=A^{T}b\)</span>. It's a least squares question and normally requires <span class="math inline">\(A^{T}A\)</span> to be non-singular. It can prove that <span class="math inline">\(rank(A)=rank(A^{T}A)\)</span>, so <span class="math inline">\(A\)</span> must have independent columns. The normal equations can be solved with Cholesky decomposition (<span class="math inline">\(A^{T}A\)</span> symm. pos. def.) but <span class="math inline">\(A^{T}A\)</span> is often ill-conditioned.</p><p>The normal equations requires less operation than other methods, but it won't work when <span class="math inline">\(A\)</span> is singular it also has a high condition number.</p><h2 id="qr-decomposition">QR decomposition</h2><p>QR decomposition <span class="math inline">\(A=QR\)</span> is one way to solve least squares problem. The solution is shown as below. <span class="math display">\[\begin{gathered}A^{T} A x=A^{T} b \Rightarrow(Q R)^{T} Q R x=(Q R)^{T} b \Rightarrow \\R^{T} Q^{T} Q R x=R^{T} Q^{T} b \Rightarrow R^{T} R x=R^{T} Q^{T} b \Rightarrow \\R x=Q^{T} b\end{gathered}\]</span> Solving <span class="math inline">\(R x=Q^{T} b\)</span> (with backward substitution) gives the least squares solution.</p><p>The merit of QR decomposition is that it has nothing to do with condition number. But the operation of QR decomposition is expensive and matrix <span class="math inline">\(A\)</span> has to be singular otherwise there will be no solution for it.</p><h2 id="persudo-inverse">Persudo-inverse</h2><p>When <span class="math inline">\(A\)</span> is a full-rank square matrix, there is a solution for <span class="math inline">\(Ax=b\)</span> that <span class="math inline">\(x=A^{-1}b\)</span>. But when <span class="math inline">\(A\)</span> isn't a full-rank square matrix, there is no solution for this equation. So we need to find the approximate solution <span class="math inline">\(x^{\prime}=\arg \min \|A x-b\|=A^{+} b\)</span>, and <span class="math inline">\(A^{+}\)</span> is a pseudo-inverse matrix.</p><p>Let the SVD of <span class="math inline">\(A\)</span> be <span class="math display">\[A=U\left(\begin{array}{ll}S &amp; 0 \\0 &amp; 0\end{array}\right) V^{T},\]</span> where <span class="math inline">\(U, V\)</span> are both orthogonal matrices, and <span class="math inline">\(S\)</span> is a diagonal matrix containing the (positive) singular values of <span class="math inline">\(A\)</span> on its diagonal. Then the pseudo-inverse of <span class="math inline">\(A\)</span> is the <span class="math inline">\(n \times m\)</span> matrix defined as <span class="math display">\[A^{+}=V\left(\begin{array}{cc}S^{-1} &amp; 0 \\0 &amp; 0\end{array}\right) U^{T} .\]</span> Note that <span class="math inline">\(A^{+}\)</span> has the same dimension as the transpose of <span class="math inline">\(A\)</span>.</p><p>If <span class="math inline">\(A\)</span> is square, invertible, then its inverse is <span class="math inline">\(A^{+}=A^{-1}\)</span>.</p><p>If <span class="math inline">\(A\)</span> is full column rank, meaning <span class="math inline">\(\operatorname{rank}(A)=n \leq m\)</span>, that is, <span class="math inline">\(A^{\top} A\)</span> is not singular, then <span class="math inline">\(A^{+}\)</span> is a left inverse of <span class="math inline">\(A\)</span>, in the sense that <span class="math inline">\(A^{+} A=I_{n}\)</span>. We have the closed-form expression <span class="math inline">\(A^{+}=\left(A^{\top} A\right)^{-1} A^{\top}\)</span></p><p>If <span class="math inline">\(A\)</span> is full row rank, meaning <span class="math inline">\(\operatorname{rank}(A)=m \leq n\)</span>, that is, <span class="math inline">\(A A^{\top}\)</span> is not singular, then <span class="math inline">\(A^{+}\)</span> is a right inverse of <span class="math inline">\(A\)</span>, in the sense that <span class="math inline">\(A A^{+}=I_{m}\)</span>. We have the closed-form expression <span class="math inline">\(A^{+}=A^{\top}\left(A A^{\top}\right)^{-1}\)</span></p><p>The solution to the least-squares problem <span class="math inline">\(\min _{x}\|A x-b\|_{2}\)</span> with minimum norm is <span class="math inline">\(x^{*}=A^{+} b\)</span>.</p><p>Persudo-inverse will work all the time but its operation is also quite expensive due to the singular value decomposition part.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The Least Squares Problem is one of the most important problem in numerical approximation. The main idea of the least squares problem is </summary>
      
    
    
    
    <category term="Mathematics" scheme="http://example.com/categories/Mathematics/"/>
    
    
    <category term="Linear Algebra" scheme="http://example.com/tags/Linear-Algebra/"/>
    
  </entry>
  
  <entry>
    <title>Cholesky Decomposition</title>
    <link href="http://example.com/2022/04/15/cholesky/"/>
    <id>http://example.com/2022/04/15/cholesky/</id>
    <published>2022-04-15T14:52:50.000Z</published>
    <updated>2022-04-15T21:59:26.125Z</updated>
    
    <content type="html"><![CDATA[<p>Cholesky decomposition is to express a symmetric positive definite matrix as a decomposition of the product of a lower triangular matrix and its transpose. It requires that all eigenvalues of the matrix must be positive, so the diagonal elements of the decomposed lower triangle are also positive. The Cholesky decomposition, also known as the square root method, is a modification of the <a href="https://imchengliang.top/2022/04/14/LU/">LU decomposition</a> when matrix A is a symmetric positive definite matrix.</p><h2 id="ldlt-decomposition">(1) LDLT decomposition</h2><p>If <span class="math inline">\(A\)</span> is symmetric, we would expect some sort of symmetry in the LU decomposition.</p><p><span class="math inline">\(U \ne L^T\)</span> due to diagonals in <span class="math inline">\(U\)</span> and <span class="math inline">\(L\)</span> not the same. But if we take <span class="math inline">\(u_{ii}\)</span> out of <span class="math inline">\(U\)</span> and store in diagonal matrix <span class="math inline">\(D\)</span> we get <span class="math inline">\(U = DL^T\)</span>, and <span class="math inline">\(A=LDL^T\)</span> called the LDLT decomposition.</p><p>It's roughly half the cost of LU decomposition as we don’t need to compute the upper diagonal part of <span class="math inline">\(U\)</span>.</p><h2 id="cholesky-decomposition">(2) Cholesky decomposition</h2><p>When <span class="math inline">\(A\)</span> is symmetric, positive definite (<span class="math inline">\(d_{ii} &lt; 0\)</span> in <span class="math inline">\(D\)</span>), the LDLT decomposition becomes Cholesky decomposition (Cholesky is stable - no pivoting needed): <span class="math display">\[A=LD^{1/2}D^{1/2}L^T=GG^T\]</span></p><p>It’s possible to calculate Cholesky directly without forming <span class="math inline">\(L\)</span> and <span class="math inline">\(D\)</span>. Use <span class="math display">\[A=\left(\begin{array}{ccc}a_{11} &amp; \cdots &amp; a_{1 n} \\\vdots &amp; \ddots &amp; \vdots \\a_{n 1} &amp; \cdots &amp; a_{n n}\end{array}\right)=\left(\begin{array}{ccc}g_{11} &amp; \cdots &amp; 0 \\\vdots &amp; \ddots &amp; \vdots \\g_{n 1} &amp; \cdots &amp; g_{n n}\end{array}\right)\left(\begin{array}{ccc}g_{11} &amp; \cdots &amp; g_{n 1} \\\vdots &amp; \ddots &amp; \vdots \\0 &amp; \cdots &amp; g_{n n}\end{array}\right)\]</span></p><h2 id="how-to-determine-matrix-is-pos.-def">(3) How to determine matrix is pos. def</h2><p>Definition <span class="math inline">\(x^{T}Ax &gt; 0\)</span> is not very useful, <span class="math inline">\(\lambda &gt; 0\)</span> works but it's too expensive to compute eigenvalues.</p><p>If not:</p><ol type="1"><li><p>Check if symmetric</p></li><li><p>Check if all diagonal elements are positive (this is just a sign of pos. def.)</p></li><li><p>Try Cholesky, and if Cholesky fail, exit and perform standard LU</p></li></ol><h2 id="cholesky-decomposition-in-python">(4) Cholesky decomposition in Python</h2><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><span class="hljs-attribute">from</span> scipy.linalg import ldl<br><span class="hljs-attribute">from</span> scipy.linalg import cholesky<br><span class="hljs-attribute">from</span> scipy.linalg import solve<br><span class="hljs-attribute">A</span>=np.array([[<span class="hljs-number">9</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">10</span>,<span class="hljs-number">7</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>]]);<br><span class="hljs-comment"># LDLT-decomposition</span><br><span class="hljs-attribute">L</span>, D, P = ldl(A,lower=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># Cholesky-decomposition</span><br><span class="hljs-attribute">G</span> = cholesky(A, lower=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># <span class="hljs-doctag">Note:</span> scipy.solve can solve systems using</span><br><span class="hljs-comment"># Cholesky. Number of operations halved.</span><br><span class="hljs-comment"># assume_a='pos' =&gt; ldlt-solution</span><br><span class="hljs-attribute">b</span> = np.array([[<span class="hljs-number">8</span>],<span class="hljs-meta"> [-1], [-4]])</span><br><span class="hljs-meta">x = solve(A,b, assume_a='pos')</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Cholesky decomposition is to express a symmetric positive definite matrix as a decomposition of the product of a lower triangular matrix </summary>
      
    
    
    
    <category term="Mathematics" scheme="http://example.com/categories/Mathematics/"/>
    
    
    <category term="Linear Algebra" scheme="http://example.com/tags/Linear-Algebra/"/>
    
  </entry>
  
  <entry>
    <title>LU Decomposition</title>
    <link href="http://example.com/2022/04/14/LU/"/>
    <id>http://example.com/2022/04/14/LU/</id>
    <published>2022-04-13T22:02:47.000Z</published>
    <updated>2022-04-15T21:49:39.343Z</updated>
    
    <content type="html"><![CDATA[<p>LU decomposition is a common method to solve polynomial <span class="math inline">\(Ax=b\)</span>, and this method is consist of three steps:</p><ol type="1"><li><p>LU factorization: Gaussian elimination on matrix <span class="math inline">\(A\)</span>, factorize <span class="math inline">\(A\)</span> to <span class="math inline">\(L,U\)</span> such that <span class="math inline">\(PA=LU\)</span></p></li><li><p>Forward substitution: Solve lower triangular system <span class="math inline">\(Ld = Pb\)</span></p></li><li><p>Backward substitution: Solve upper triangular system <span class="math inline">\(Ux = d\)</span></p></li></ol><p>In the following part, I would use the example of <span class="math inline">\(A\)</span> and <span class="math inline">\(b\)</span> to explain the calculation of LU decomposition. <span class="math display">\[A=\left(\begin{array}{ccc}1 &amp; 2 &amp; 3 \\2 &amp; 5 &amp; 10 \\3 &amp; 10 &amp; 10\end{array}\right), \quad b=\left(\begin{array}{c}3 \\7 \\13\end{array}\right)\]</span></p><h2 id="lu-factorization">(1) LU factorization</h2><p>In LU factorization, we need to factorize <span class="math inline">\(A\)</span> into <span class="math inline">\(L\)</span> and <span class="math inline">\(U\)</span>, and let <span class="math inline">\(LU=PA\)</span> <span class="math display">\[L=\left(\begin{array}{ccc}a_1 &amp; 0 &amp; 0 \\a_2 &amp; a_3 &amp; 0 \\a_4 &amp; a_5 &amp; a_6\end{array}\right), \quad U=\left(\begin{array}{ccc}b_1 &amp; b_2 &amp; b_3 \\0 &amp; b_4 &amp; b_5 \\0 &amp; 0 &amp; b_6\end{array}\right)\]</span></p><p>Sometimes, we can get the right result through the decomposition of <span class="math inline">\(LU=A\)</span>, but this decomposition isn't stable that might cause a large error in the calculation. Therefore, we need to do the "pivoting" procedure (<span class="math inline">\(P\)</span>) during the factorization step. "pivoting" means that we should keep the value of each non-zero element of each row to be larger the other elements of the same column below this one, and we can achieve this goal by row exchange.</p><p><span class="math inline">\(U\)</span> is obtained from Gaussian elimination of <span class="math inline">\(A\)</span>, and <span class="math inline">\(L\)</span> is computed from <span class="math inline">\(U\)</span>. <span class="math inline">\(P\)</span> is the identity matrix at first, and if we exchange row during the Gaussian elimination, the same exchange need to be applied on <span class="math inline">\(P\)</span>. And <span class="math inline">\(A, P, L, U\)</span> all have the same size.</p><p>The calculation below is LU factorization example:</p><p><span class="math display">\[\begin{aligned}&amp;A=\left(\begin{array}{ccc}1 &amp; 2 &amp; 3 \\2 &amp; 5 &amp; 10 \\3 &amp; 10 &amp; 16\end{array}\right), \quad P=\left(\begin{array}{lll}1 &amp; 0 &amp; 0 \\0 &amp; 1 &amp; 0 \\0 &amp; 0 &amp; 1\end{array}\right) \\&amp;\stackrel{R_{1} \leftrightarrow R_{3}}{\longrightarrow}\left(\begin{array}{ccc}3 &amp; 10 &amp; 16 \\2 &amp; 5 &amp; 10 \\1 &amp; 2 &amp; 3\end{array}\right), \quad P=\left(\begin{array}{lll}0 &amp; 0 &amp; 1 \\0 &amp; 1 &amp; 0 \\1 &amp; 0 &amp; 0\end{array}\right) \\&amp;\stackrel{R_{2}-\frac{2}{3} R_{1}}{\longrightarrow}\left(\begin{array}{ccc}3 &amp; 10 &amp; 10 \\0 &amp; -\frac{5}{3} &amp; -\frac{2}{3} \\0 &amp; -\frac{4}{3} &amp; -\frac{1}{3}\end{array}\right), \quad P=\left(\begin{array}{lll}0 &amp; 0 &amp; 1 \\0 &amp; 1 &amp; 0 \\1 &amp; 0 &amp; 0\end{array}\right) \\&amp;\stackrel{R_{3}-\frac{1}{5} R_{1} R_{2}}{\longrightarrow}\left(\begin{array}{ccc}3 &amp; 10 &amp; 16 \\0 &amp; -\frac{5}{3} &amp; -\frac{2}{3} \\0 &amp; 0 &amp; -\frac{5}{5}\end{array}\right)=U, \quad P=\left(\begin{array}{lll}0 &amp; 0 &amp; 1 \\0 &amp; 1 &amp; 0 \\1 &amp; 0 &amp; 0\end{array}\right)\end{aligned}\]</span></p><p><span class="math display">\[\begin{aligned}L&amp;=\left(\left(\begin{array}{l}3 \\2 \\1\end{array}\right) / 3,\left(\begin{array}{c}0 \\-\frac{5}{3} \\-\frac{4}{3}\end{array}\right) / -\frac{5}{3},\left(\begin{array}{c}0 \\0 \\-\frac{9}{5}\end{array}\right) /-\frac{9}{5}\right) \\&amp;=\left(\begin{array}{ccc}1 &amp; 0 &amp; 0 \\\frac{2}{3} &amp; 1 &amp; 0 \\\frac{1}{3} &amp; \frac{4}{5} &amp; 1\end{array}\right)\end{aligned}\]</span></p><h2 id="forward-and-backward-substitution">(2) Forward and Backward substitution</h2><p>Forward and Backward substitution is used to calculate the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> in the following functions. <span class="math display">\[\begin{aligned}&amp;\left\{\begin{array} { l } { A x = b } \\{ L U = P A } \\{ U x = y }\end{array} \rightarrow \left\{\begin{array}{l}L y=P b \\U x=y\end{array}\right.\right.\\\end{aligned}\]</span> Forward substitution: <span class="math display">\[\begin{aligned}&amp;P b=\left(\begin{array}{lll}0 &amp; 0 &amp; 1 \\0 &amp; 1 &amp; 0 \\1 &amp; 0 &amp; 0\end{array}\right) \cdot\left(\begin{array}{l}3 \\7 \\13\end{array}\right)=\left(\begin{array}{c}13 \\7 \\3\end{array}\right)\\&amp;L y=\left(\begin{array}{ccc}1 &amp; 0 &amp; 0 \\\frac{2}{3} &amp; 1 &amp; 0 \\\frac{1}{3} &amp; \frac{4}{5} &amp; 1\end{array}\right) \cdot\left(\begin{array}{l}y_{1} \\y_{2} \\y_{3}\end{array}\right)=\left(\begin{array}{c}13 \\7 \\3\end{array}\right)\\&amp;\rightarrow\left\{\begin{array} { l } { y _ { 1 } = 1 3 } \\{ \frac { 2 } { 3 } y _ { 1 } + y _ { 2 } = 1 } \\{ \frac { 1 } { 3 } y _ { 1 } + \frac { 4 } { 5 } y _ { 2 } + y _ { 3 } = 3 }\end{array} \rightarrow \left\{\begin{array}{l}y_{1}=13 \\y_{2}=-\frac{5}{3} \\y_{3}=0\end{array} \quad \rightarrow y=\left(\begin{array}{c}13 \\-\frac{5}{3} \\0\end{array}\right)\right.\right.\\\end{aligned}\]</span> Backward substitution: <span class="math display">\[\begin{aligned}&amp;Ux=\left(\begin{array}{ccc}3 &amp; 10 &amp; 16 \\0 &amp; -\frac{5}{3} &amp; -\frac{2}{3} \\0 &amp; 0 &amp; -\frac{9}{5}\end{array}\right) \cdot\left(\begin{array}{l}x_{1} \\x_{2} \\x_{3}\end{array}\right)=\left(\begin{array}{c}13 \\-\frac{5}{3} \\0\end{array}\right)\\&amp;\rightarrow\left\{\begin{array} { c } { 3 x _ { 1 } + 1 0 x _ { 2 } + 1 6 x _ { 3 } = 1 3 } \\{ - \frac { 5 } { 3 } x _ { 2 } - \frac { 2 } { 3 } x _ { 3 } = - \frac { 5 } { 3 } } \\{ - \frac { 9 } { 5 } x _ { 3 } = 0 }\end{array} \rightarrow \left\{\begin{array}{l}x_{1}=1 \\x_{2}=1 \\x_{3}=0\end{array} \rightarrow x=\left(\begin{array}{l}1 \\1 \\0\end{array}\right)\right.\right.\end{aligned}\]</span></p><h2 id="lu-decomposition-in-python">(3) LU decomposition in Python</h2><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import numpy as np<br><span class="hljs-keyword">from</span> scipy.linalg import lu<br><span class="hljs-keyword">from</span> scipy.linalg import solve_triangular<br><span class="hljs-attribute">A</span>=np.array([[3 -1 2],[1 0 -1],[4 2 -3]])<br>P, L, U =lu(A)<br><span class="hljs-attribute">b</span>=np.array([[8],[-1],[-4]])<br>b = P.T @ b # Row changes <span class="hljs-keyword">in</span> b<br><span class="hljs-comment"># Forward and backward substitution</span><br><span class="hljs-attribute">d</span>=solve_triangular(L, b, <span class="hljs-attribute">lower</span>=<span class="hljs-literal">True</span>)<br><span class="hljs-attribute">x</span>=solve_triangular(U, y)<br><span class="hljs-comment"># Check if the result from LU-decomposition is the same as direct computation</span><br>x2 = np.linalg.solve(A,b) <br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;LU decomposition is a common method to solve polynomial &lt;span class=&quot;math inline&quot;&gt;\(Ax=b\)&lt;/span&gt;, and this method is consist of three st</summary>
      
    
    
    
    <category term="Mathematics" scheme="http://example.com/categories/Mathematics/"/>
    
    
    <category term="Linear Algebra" scheme="http://example.com/tags/Linear-Algebra/"/>
    
  </entry>
  
  <entry>
    <title>Introduction to Docker-Compose</title>
    <link href="http://example.com/2022/04/13/docker-compose/"/>
    <id>http://example.com/2022/04/13/docker-compose/</id>
    <published>2022-04-13T20:27:36.000Z</published>
    <updated>2022-04-13T21:58:12.233Z</updated>
    
    <content type="html"><![CDATA[<p>Docker-Compose is used to manage your containers, kind of like a container steward. We write a file, declare the container to be started in this file, configure some parameters, execute this file, Docker will start all containers according to the declared configuration.</p><p>Here is an example to build a multi-container Apache Spark cluster using docker-compose.</p><h2 id="create-a-file-name-dockerfile-and-add-the-following-contents-in-the-file">(1) Create a file name “Dockerfile ” and add the following contents in the file</h2><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">FROM</span> ubuntu:<span class="hljs-number">20</span>.<span class="hljs-number">04</span><br><span class="hljs-attribute">RUN</span> apt-get update<br><span class="hljs-attribute">RUN</span> apt-get -y upgrade<br><span class="hljs-attribute">RUN</span> apt install -y openjdk-<span class="hljs-number">8</span>-jre-headless<br><span class="hljs-attribute">RUN</span> apt install -y scala<br><span class="hljs-attribute">RUN</span> apt install -y wget<br><span class="hljs-attribute">RUN</span> apt install -y screen<br><span class="hljs-attribute">RUN</span> wget https://archive.apache.org/dist/spark/ spark-<span class="hljs-number">3</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span>/spark-<span class="hljs-number">3</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span>-bin-hadoop<span class="hljs-number">3</span>.<span class="hljs-number">2</span>.tgz<br><span class="hljs-attribute">RUN</span> tar xvf spark-<span class="hljs-number">3</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span>-bin-hadoop<span class="hljs-number">3</span>.<span class="hljs-number">2</span>.tgz<br><span class="hljs-attribute">RUN</span> mv spark-<span class="hljs-number">3</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span>-bin-hadoop<span class="hljs-number">3</span>.<span class="hljs-number">2</span>/ /usr/local/spark ENV PATH=<span class="hljs-string">"${PATH}:$SPARK_HOME/bin"</span><br><span class="hljs-attribute">ENV</span> SPARK_HOME=<span class="hljs-string">"/usr/local/spark"</span><br><span class="hljs-attribute">ENV</span> SPARK_NO_DAEMONIZE=<span class="hljs-string">"true"</span><br><span class="hljs-attribute">RUN</span> sleep <span class="hljs-number">15</span><br><span class="hljs-attribute">CMD</span> screen -d -m $SPARK_HOME/sbin/start-master.sh ; $SPARK_HOME/sbin/start-worker.sh spark://sparkmaster:<span class="hljs-number">7077</span><br></code></pre></td></tr></tbody></table></figure><h2 id="build-the-image-based-on-the-dockerfile-and-run-the-container">(2) Build the image based on the Dockerfile and run the container</h2><figure class="highlight applescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs applescript">docker build -t sparkaio/<span class="hljs-keyword">first</span>:v0 .<br>docker <span class="hljs-built_in">run</span> -h sparkmaster &lt;Generated-Image-ID <span class="hljs-keyword">or</span> image <span class="hljs-built_in">name</span>&gt;<br></code></pre></td></tr></tbody></table></figure><p>The following commands are used to confirm that the spark setup is working correctly </p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">docker exec -it container_id <span class="hljs-regexp">/bin/</span>bash<br><span class="hljs-variable">$SPARK_HOME</span><span class="hljs-regexp">/bin/</span>spark-submit --class org.apache.spark.examples.SparkPi --master spark:<span class="hljs-regexp">//</span>sparkmaster:<span class="hljs-number">7077</span> <span class="hljs-variable">$SPARK_HOME</span><span class="hljs-regexp">/examples/</span>jars/spark-examples_2.<span class="hljs-number">12</span>-<span class="hljs-number">3.2</span>.<span class="hljs-number">0</span>.jar<br></code></pre></td></tr></tbody></table></figure><p></p><p>Based on the above configurations, a single container-based Spark framework has been created.​ Next step is to prepare a configuration file, compatible with docker-compose, and run a Spark cluster with at least one master node and one additional worker.</p><h2 id="create-a-docker-compose.yml-file-and-write-the-configuration-on-this-file">(3) Create a docker-compose.yml file and write the configuration on this file</h2><p>Here, we set 1 master and 1 worker for the Spark cluster.</p><figure class="highlight dts"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">version:</span> <span class="hljs-string">"2"</span><br><span class="hljs-symbol">services:</span><br><span class="hljs-symbol">  master:</span><br><span class="hljs-symbol">    image:</span> sparkaio/first:v0<br><span class="hljs-symbol">    command:</span> <span class="hljs-meta-keyword">/usr/</span>local<span class="hljs-meta-keyword">/spark/</span>sbin/start-master.sh<br><span class="hljs-symbol">    hostname:</span> master<br><span class="hljs-symbol">    ports:</span><br>      - <span class="hljs-string">"6066:6066"</span><br>      - <span class="hljs-string">"7070:7070"</span><br>      - <span class="hljs-string">"8080:8080"</span><br>      - <span class="hljs-string">"50070:50070"</span><br><span class="hljs-symbol">  worker:</span><br><span class="hljs-symbol">    image:</span> sparkaio/first:v0<br><span class="hljs-symbol">    command:</span> <span class="hljs-meta-keyword">/usr/</span>local<span class="hljs-meta-keyword">/spark/</span>sbin/start-worker.sh<br><span class="hljs-symbol">    links:</span><br>      - master<br></code></pre></td></tr></tbody></table></figure><h2 id="startup-and-shutdown-of-docker-compose">(4) Startup and shutdown of docker-compose</h2><figure class="highlight crmsh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs crmsh"><span class="hljs-comment"># We can start the container by using up</span><br>docker-compose up<br><span class="hljs-comment"># After the first time, we can simply use start to start the services</span><br>docker-compose <span class="hljs-literal">start</span><br><span class="hljs-comment"># To safely stop the active services, we can use stop</span><br>docker-compose <span class="hljs-literal">stop</span><br><span class="hljs-comment"># To reset the status of the project, we simply run down</span><br>docker-compose down<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Docker-Compose is used to manage your containers, kind of like a container steward. We write a file, declare the container to be started </summary>
      
    
    
    
    <category term="Data Engineering" scheme="http://example.com/categories/Data-Engineering/"/>
    
    
    <category term="Docker" scheme="http://example.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Basic Use of Docker</title>
    <link href="http://example.com/2022/04/13/docker/"/>
    <id>http://example.com/2022/04/13/docker/</id>
    <published>2022-04-13T09:32:34.000Z</published>
    <updated>2022-04-13T20:31:56.714Z</updated>
    
    <content type="html"><![CDATA[<p>Docker is an open source application container that allows developers to package their applications and dependencies into a portable engine, and then publish them to operating system such as Linux or Windows for virtualization.</p><p>This blog covers basic introduction of the Docker environment, Dockerfile settings and construction of a multi-container environment using docker-compose (one of the essential tools to build, connect and run multiple containers).</p><h2 id="docker-containers">(1) Docker containers</h2><p>The following commands are used to install docker on virtual machine:</p><figure class="highlight smali"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs smali">sudo bash<br>apt update; apt -y upgrade;<br><span class="hljs-comment"># Install the required packages</span><br>apt install apt-transport-https ca-certificates curl software-properties-common<br><span class="hljs-comment"># Add the GPG key for the official Docker repository to the system</span><br>curl -fsSL https://download.docker.com/ linux/ubuntu/gpg |sudo apt-key<span class="hljs-built_in"> add </span>-<br><span class="hljs-comment"># Add the Docker repository to APT sources</span><span class="hljs-built_in"></span><br><span class="hljs-built_in">add-apt-repository </span><span class="hljs-string">"deb [arch=amd64] https:// download.docker.com/linux/ubuntu bionic stable"</span><br><span class="hljs-comment"># Update the package database with the Docker packages from the newly added repo</span><br>apt-get update<br><span class="hljs-comment"># Install Docker</span><br>apt install docker-ce<br><span class="hljs-comment"># Check if docker has started</span><span class="hljs-keyword"></span><br><span class="hljs-keyword">system</span>ctl status docker<br></code></pre></td></tr></tbody></table></figure><p>Then create a file name “Dockerfile ” and add the following contents in the file: </p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-keyword">FROM</span> ubuntu:20.04<br><span class="hljs-builtin-name">RUN</span> apt-<span class="hljs-builtin-name">get</span> update<br><span class="hljs-builtin-name">RUN</span> apt-<span class="hljs-builtin-name">get</span> -y<span class="hljs-built_in"> upgrade</span><br><span class="hljs-built_in"></span><span class="hljs-builtin-name">RUN</span> apt-<span class="hljs-builtin-name">get</span> install sl<br>ENV <span class="hljs-attribute">PATH</span>=<span class="hljs-string">"<span class="hljs-variable">${PATH}</span>:/usr/games/"</span><br>CMD [<span class="hljs-string">"echo"</span>, <span class="hljs-string">"Data Engineering-I."</span>]<br></code></pre></td></tr></tbody></table></figure><p></p><p>Contextualize a container (create a new image that is contextualized according to the Dockerfile and start a container based on the contextualized image): </p><figure class="highlight applescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs applescript">docker build -t mycontainer/<span class="hljs-keyword">first</span>:v1 .<br><span class="hljs-comment"># In batch mode</span><br>docker <span class="hljs-built_in">run</span> mycontainer/<span class="hljs-keyword">first</span>:v1<br><span class="hljs-comment"># In interactive mode:</span><br>docker <span class="hljs-built_in">run</span> -<span class="hljs-keyword">it</span> mycontainer/<span class="hljs-keyword">first</span>:v1 bash<br></code></pre></td></tr></tbody></table></figure><p></p><p>Now we have a running docker container with some extra packages installed in it.</p><h2 id="dockerhub">(2) DockerHub</h2><p><a href="https://hub.docker.com/">DockerHub</a> is used to store the Docker images, and developers also can use the images that are stored on DockerHub so the required development-environment can be built quickly. To use DockerHub, we need to create an account on its official website firstly. And the following commands are use to operate DockerHub on virtual machine.</p><figure class="highlight vala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs vala"><span class="hljs-meta"># login the DockerHub account on virtual machine</span><br>docker login<br><span class="hljs-meta"># then input the username and password</span><br><br><span class="hljs-meta"># upload image to DockerHub</span><br><span class="hljs-meta"># docker tag 'image-name:tag-name or image-ID' 'username/ image-name:tag-name'</span><br>docker tag e7083fd898c7 arnieswap/my_repo:testing<br>docker push arnieswap/my_repo<br><span class="hljs-meta"># check if it's pushed successfully</span><br>docker search arnieswap/my_repo<br><br><span class="hljs-meta"># download image from DockerHub</span><br>docker pull arnieswap/my_repo<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Docker is an open source application container that allows developers to package their applications and dependencies into a portable engi</summary>
      
    
    
    
    <category term="Data Engineering" scheme="http://example.com/categories/Data-Engineering/"/>
    
    
    <category term="Docker" scheme="http://example.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Norms and Condition Number</title>
    <link href="http://example.com/2022/03/28/subspace-1/"/>
    <id>http://example.com/2022/03/28/subspace-1/</id>
    <published>2022-03-28T12:27:12.000Z</published>
    <updated>2022-04-11T21:22:08.653Z</updated>
    
    <content type="html"><![CDATA[<p>Norm is a function from a real or complex vector space to the non-negative real numbers that behaves in certain ways, which can be used to measure the size of vectors (vector norm) and matrices (matrix norm). And norm is denoted by <span class="math inline">\(\parallel . \parallel\)</span>.</p><p>The condition number is an application of the derivative, and is formally defined as the value of the asymptotic worst-case relative change in output for a relative change in input. The "function" is the solution of a problem and the "arguments" are the data in the problem, so the condition number depends on the nature of the underlying problem.</p><h2 id="conditions-of-norms">Conditions of Norms</h2><p>To be valid and useful as norms, all norms must satisfy the following conditions:</p><ol type="1"><li><p><span class="math inline">\(\parallel A \parallel\)</span> <span class="math inline">\(\ge 0\)</span> for vectors <span class="math inline">\(\parallel x \parallel\)</span> <span class="math inline">\(\ge 0\)</span></p></li><li><p><span class="math inline">\(\parallel A \parallel\)</span> <span class="math inline">\(= 0\)</span> if and only if <span class="math inline">\(A=0\)</span></p></li><li><p><span class="math inline">\(\parallel \alpha A \parallel\)</span> = <span class="math inline">\(\mid \alpha\mid.\parallel A \parallel\)</span></p></li><li><p><span class="math inline">\(\parallel A+B \parallel\)</span> <span class="math inline">\(\le\)</span> <span class="math inline">\(\parallel A \parallel + \parallel B \parallel\)</span>, triangle inequality<br></p></li><li><p><span class="math inline">\(\parallel AB \parallel\)</span> <span class="math inline">\(\le\)</span> <span class="math inline">\(\parallel A \parallel . \parallel B \parallel\)</span>, Cauchy-Schwarz inequality also <span class="math inline">\(\parallel Ax \parallel\)</span> <span class="math inline">\(\le\)</span> <span class="math inline">\(\parallel A \parallel . \parallel x \parallel\)</span> is valid</p></li></ol><h2 id="vector-norms">Vector Norms</h2><p>2-norm is most used but which one to use depends on the application. Let <span class="math inline">\(x\)</span> be a vector of length <span class="math inline">\(n\)</span></p><ol type="1"><li><p>2-norm, Euclidian norm:<br><span class="math inline">\(\|x\|_{2}=\sqrt{\left|x_{1}\right|^{2}+\left|x_{2}\right|^{2}+\cdots+\left|x_{n}\right|^{2}}=\sqrt{x^{T} x}\)</span></p></li><li><p>1-norm, minimum norm:<br><span class="math inline">\(\|x\|_{1}=\left|x_{1}\right|+\left|x_{2}\right|+\cdots+\left|x_{n}\right|\)</span></p></li><li><p><span class="math inline">\(\infty\)</span> -norm, maximum norm:<br><span class="math inline">\(\|x\|_{\infty}=\max _{i}\left\{\left|x_{1}\right|, \ldots,\left|x_{n}\right|\right\}\)</span></p></li></ol><h2 id="matrix-norms">Matrix Norms</h2><ol type="1"><li><p>Frobenius norm (straightforward extension of the Euclidean norm):<br><span class="math inline">\(\|A\|_{F}=\sqrt{\sum_{i=1}^{m} \sum_{i=1}^{n} a_{i j}^{2}}\)</span></p></li><li><p>Another common matrix norm (<span class="math inline">\(Ax\)</span> and <span class="math inline">\(x\)</span> are vectors):<br><span class="math inline">\(\|A\|=\max _{x \neq 0} \frac{\|A x\|}{\|x\|}\)</span></p></li></ol><h2 id="norms">Norms</h2><ol type="1"><li><p>1-norm, min norm, <span class="math inline">\(l_1\)</span>-norm:<br><span class="math inline">\(\|A\|_{1} = \max _{1 \le j \le n} \sum_{i=1}^{m} \left|a_{ij}\right|\)</span></p></li><li><p><span class="math inline">\(\infty\)</span>-norm, max norm, <span class="math inline">\(l_{\infty}\)</span>-norm:<br><span class="math inline">\(\|A\|_{\infty} = \max _{1 \le i \le m} \sum_{j=1}^{n} \left|a_{ij}\right|\)</span></p></li><li><p>2-norm, Euclidian/spectral norm, <span class="math inline">\(l_2\)</span>-norm (<span class="math inline">\(\lambda(A^{T}A)\)</span> are the eigenvalues of <span class="math inline">\(A^{T}A\)</span>):<br><span class="math inline">\(\|A\|_{2} = \sqrt{\max \{ \lambda (A^{T}A)\}}\)</span><br></p></li></ol><h2 id="norm-calculation-in-python">Norm Calculation in Python</h2><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><span class="hljs-attribute">A</span> = np.array([[<span class="hljs-number">1</span>,-<span class="hljs-number">2</span>],[<span class="hljs-number">6</span>,<span class="hljs-number">4</span>]])<br><span class="hljs-comment"># 1-norm</span><br><span class="hljs-attribute">np</span>.linalg.norm(A,<span class="hljs-number">1</span>)<br><span class="hljs-comment"># max-norm</span><br><span class="hljs-attribute">np</span>.linalg.norm(A,np.inf)<br><span class="hljs-comment"># 2-norm</span><br><span class="hljs-attribute">np</span>.linalg.norm(A,<span class="hljs-number">2</span>) <br><span class="hljs-comment"># Frobenius</span><br><span class="hljs-attribute">np</span>.linalg.norm(A,’fro’)<br><span class="hljs-comment"># Default</span><br><span class="hljs-attribute">np</span>.linalg.norm(A)            <br></code></pre></td></tr></tbody></table></figure><h2 id="characteristics-of-condition-number">Characteristics of Condition Number</h2><ol type="1"><li><p>A very big condition number suggests that matrix close to singular (<span class="math inline">\(cond \approx 10^{16}\)</span>), and it also means that the system is sensitive to these perturbations.</p></li><li><p>Best possible case: Condition number = 1<br><span class="math inline">\(cond(A)\)</span> <span class="math inline">\(=\)</span> <span class="math inline">\(\parallel A^{-1} \parallel . \parallel A \parallel\)</span> <span class="math inline">\(\le\)</span> <span class="math inline">\(\parallel A^{-1}A \parallel\)</span> <span class="math inline">\(=\)</span> <span class="math inline">\(\parallel I \parallel\)</span> <span class="math inline">\(= 1\)</span><br>meaning no magnification at all</p></li><li><p>No sharp definition for what’s large/small.</p></li><li><p>Condition number also tends to get bigger when matrix size increases.</p></li></ol><h2 id="condition-number-calculation-in-python">Condition Number Calculation in Python</h2><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><span class="hljs-attribute">A</span> = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">1</span>,-<span class="hljs-number">1</span>]])<br><span class="hljs-comment"># 1-norm condition no.</span><br><span class="hljs-attribute">np</span>.linalg.cond(A,<span class="hljs-number">1</span>)      <br><span class="hljs-comment"># max-norm condition no.</span><br><span class="hljs-attribute">np</span>.linalg.cond(A,np.inf) <br><span class="hljs-comment"># 2-norm condition no.</span><br><span class="hljs-attribute">np</span>.linalg.cond(A,<span class="hljs-number">2</span>)      <br><span class="hljs-comment"># Frobenius condition no.</span><br><span class="hljs-attribute">np</span>.linalg.cond(A,’fro’)  <br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Norm is a function from a real or complex vector space to the non-negative real numbers that behaves in certain ways, which can be used t</summary>
      
    
    
    
    <category term="Mathematics" scheme="http://example.com/categories/Mathematics/"/>
    
    
    <category term="Linear Algebra" scheme="http://example.com/tags/Linear-Algebra/"/>
    
  </entry>
  
  <entry>
    <title>Subspace</title>
    <link href="http://example.com/2022/03/27/subspace/"/>
    <id>http://example.com/2022/03/27/subspace/</id>
    <published>2022-03-27T21:06:00.000Z</published>
    <updated>2022-04-07T11:10:20.883Z</updated>
    
    <content type="html"><![CDATA[<p>In Linear Algebra, linear subspace is also known as vector subspace, which is a subset of a larger <a href="https://imchengliang.top/2021/12/23/post/">vector space</a>. A linear subspace is normally called as subspace when the context serves to distinguish it from other types of subspaces.</p><p>For all subspace <span class="math inline">\(U\)</span>, they have to satisfy the following 3 rules:</p><ol type="1"><li><p>Additive identity <span class="math inline">\(0, u \in U\)</span>, and <span class="math inline">\(0+u = u+0\)</span>, <span class="math inline">\(0\)</span> and <span class="math inline">\(u\)</span> here are vectors.</p></li><li><p>Close under addition For all <span class="math inline">\(u, w \in U\)</span>, then <span class="math inline">\(u+w \in U\)</span>, <span class="math inline">\(u\)</span> and <span class="math inline">\(w\)</span> here are vectors.</p></li><li><p>Close under scalar multiplication For all <span class="math inline">\(u \in U\)</span>, <span class="math inline">\(k \in R\)</span>, then <span class="math inline">\(k*u \in U\)</span>, <span class="math inline">\(u\)</span> is a vector and <span class="math inline">\(k\)</span> is a constant.</p></li></ol><p>Suppose that <span class="math inline">\(A\)</span> is a <span class="math inline">\(m * n\)</span> matrix that maps vectors in <span class="math inline">\(R^n\)</span> to vectors in <span class="math inline">\(R^m\)</span>. The four fundamental subspaces associated with <span class="math inline">\(A\)</span>, two in <span class="math inline">\(R^n\)</span> and two in <span class="math inline">\(R^n\)</span>.</p><p><span class="math display">\[A=\left(\begin{array}{ll}a_{11} &amp; \dots &amp; a_{1n}\\\dots &amp; \dots &amp; \dots\\a_{m1} &amp; \dots &amp; a_{mn}\end{array}\right) = \left(\begin{array}{ll}1 &amp; 3 &amp; 3 \\2 &amp; 4 &amp; 6 \\1 &amp; 7 &amp; 3\end{array}\right) \in M_{m,n}(R) = M_{3,3}(R)\]</span></p><h2 id="column-space">Column Space</h2><p>The column space of A is the linear combination of all linearly independent non-zero columns in A (it works with or without Gaussian elimination), i.e. <span class="math inline">\(Ax\)</span>, subspace in <span class="math inline">\(R^m\)</span>.</p><p>So <span class="math inline">\(C(A)\)</span> span <span class="math inline">\(\left\{\left(\begin{array}{c}a_{11} \\ \vdots \\ a_{m 1}\end{array}\right) \cdots\left(\begin{array}{c}a_{1 n} \\ \vdots \\ a_{m n}\end{array}\right) \right\}\)</span> , and the rank of A is equal to the dimension of column space.</p><p>We apply Gaussian elimination on matrix A, then get <span class="math inline">\(A=\left(\begin{array}{lll} 1 &amp; 3 &amp; 3 \\ 2 &amp; 4 &amp; 6 \\ 1 &amp; 7 &amp; 3 \end{array}\right) {\longrightarrow}\left(\begin{array}{lll} 1 &amp; 0 &amp; 3 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{array}\right)\)</span>.</p><p>Because column 1 and column 3 are not linearly independent, <span class="math inline">\(C(A)\)</span> is the linear combination of column 2 and column 1 or column 2 and column 3, either of these two is correct.</p><p>If we choose column 1 and column 2, then <span class="math inline">\(C(A) = \left\{\left(\begin{array}{c}1 \\ 0 \\ 0\end{array}\right) , \left(\begin{array}{c}0 \\ 1 \\ 0\end{array}\right) \right\}\)</span>, and <span class="math inline">\(Rank(A) = dim(C(A)) = 2\)</span>.</p><h2 id="row-space">Row Space</h2><p>The row space of A is the linear combination of all non-zero rows in A after Gaussian elimination, i.e. <span class="math inline">\(A^{T}y\)</span>, subspace in <span class="math inline">\(R^n\)</span>.</p><p>So <span class="math inline">\(R(A) = C(A^T)\)</span> span <span class="math inline">\(\left\{\left(a_{11} \ldots a_{1 n}\right) \cdots\left(a_{m 1} \cdots a_{m n}\right)\right\}\)</span>.</p><p>According to Gaussian elimination, we get <span class="math inline">\(A {\rightarrow}\left(\begin{array}{lll} 1 &amp; 0 &amp; 3 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{array}\right)\)</span>, then row space of A is the non-zero rows (row 1 and row 2), <span class="math inline">\(R(A)=\left\{\left(1, 0, 3\right),\left(0, 1, 0\right)\right\}\)</span>.</p><h2 id="nullspace">Nullspace</h2><p>The nullspace of A is the linear combination of all solution of <span class="math inline">\(Ax = 0\)</span>, subspace in <span class="math inline">\(R^n\)</span>.</p><p>According to Gaussian elimination, we get <span class="math inline">\(A {\rightarrow}\left(\begin{array}{lll} 1 &amp; 0 &amp; 3 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{array}\right)\)</span>, then we get<br></p><p><span class="math inline">\(\left(\begin{array}{lll}1 &amp; 0 &amp; 3 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0\end{array}\right) \cdot\left(\begin{array}{l}x_{1} \\ x_{2} \\ x_{3}\end{array}\right)=\left\{\begin{array}{c}x_{1}+3 x_{3}=0 \\ x_{2}=0\end{array} \rightarrow\left\{\begin{array}{c}x_{1}=-3 x_{3} \\ x_{2}=0 \\ x_{3} \in R\end{array} \rightarrow x=N(A)=\left(\begin{array}{c}-3 \\ 0 \\ 1\end{array}\right) \cdot x_{3}\right.\right.\)</span><br></p><p>So a basis of <span class="math inline">\(N(A)\)</span> is <span class="math inline">\((-3, 0, 1 )\)</span>, and nullity of A: <span class="math inline">\(null(A) = dim(N(A)) = 1\)</span>.</p><h2 id="left-nullspace">Left Nullspace</h2><p>The left nullspace of A is the linear combination of all solution of <span class="math inline">\(A^{T}y = 0\)</span>, subspace in <span class="math inline">\(R^m\)</span>.</p><p>We apply Gaussian elimination on matrix <span class="math inline">\(A^T\)</span>, then get <span class="math inline">\(A^T=\left(\begin{array}{lll} 1 &amp; 2 &amp; 1 \\ 3 &amp; 4 &amp; 7 \\ 3 &amp; 6 &amp; 3 \end{array}\right) {\longrightarrow}\left(\begin{array}{lll} 1 &amp; 0 &amp; 5 \\ 0 &amp; 1 &amp; -2 \\ 0 &amp; 0 &amp; 0 \end{array}\right)\)</span><br></p><p><span class="math inline">\(\left(\begin{array}{lll}1 &amp; 0 &amp; 5 \\ 0 &amp; 1 &amp; -2 \\ 0 &amp; 0 &amp; 0\end{array}\right) \cdot\left(\begin{array}{l}y_{1} \\ y_{2} \\ y_{3}\end{array}\right)=\left\{\begin{array}{c}y_{1}+5 y_{3}=0 \\ y_{2}-2y_{3}=0\end{array} \rightarrow\left\{\begin{array}{c}y_{1}=-5 y_{3} \\ y_{2}=2 y_{3} \\ y_{3} \in R\end{array} \rightarrow y=N(A^T)=\left(\begin{array}{c}-5 \\ 2 \\ 1\end{array}\right) \cdot y_{3}\right.\right.\)</span> &nbsp;<br></p><p>So a basis of <span class="math inline">\(N(A^T)\)</span> is <span class="math inline">\((-5, 2, 1 )\)</span>, and <span class="math inline">\(null(A^T) = dim(N(A^T)) = 1\)</span>.</p><h2 id="characteristic-of-these-four-subspaces">Characteristic of these four subspaces</h2><ol type="1"><li>Orthogonal: Column space and left nullspace are orthogonal, row space and null space are orthogonal.<br></li></ol><p><span class="math inline">\(C(A) \perp N\left(A^{\top}\right) \rightarrow(1,2,1) \cdot\left(\begin{array}{c}-5 \\ 2 \\ 1\end{array}\right)=(3,4,7) \cdot\left(\begin{array}{c}-5 \\ 2 \\ 1\end{array}\right)=0\)</span><br></p><p><span class="math inline">\(R(A) \perp N(A) \rightarrow(1,0,3) \cdot\left(\begin{array}{c}-3 \\ 0 \\ 1\end{array}\right)=(0,1,0) \cdot\left(\begin{array}{c}-3 \\ 0 \\ 1\end{array}\right)=0\)</span></p><ol start="2" type="1"><li>Rank-nullity:</li></ol><p>Rank + Nullity = Column Number<br></p><p>dim(Row Space) + dim(Left Nullsapce) = Row Number</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In Linear Algebra, linear subspace is also known as vector subspace, which is a subset of a larger &lt;a href=&quot;https://imchengliang.top/2021</summary>
      
    
    
    
    <category term="Mathematics" scheme="http://example.com/categories/Mathematics/"/>
    
    
    <category term="Linear Algebra" scheme="http://example.com/tags/Linear-Algebra/"/>
    
  </entry>
  
  <entry>
    <title>Run Word-Count Example of Hadoop (Python Version)</title>
    <link href="http://example.com/2022/02/16/hadoop-on-cloud-python/"/>
    <id>http://example.com/2022/02/16/hadoop-on-cloud-python/</id>
    <published>2022-02-16T13:59:18.000Z</published>
    <updated>2022-04-13T09:21:22.689Z</updated>
    
    <content type="html"><![CDATA[<p>While Hadoop/MapReduce is based on Java, it is not necessary to use Java to write the mapper and reducer. The Hadoop framework provides the “Streaming API”, which lets us use any command line executable that reads from standard input and writes to standard output as the mapper or reducer. This tutorial (<a href="https://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/">Link</a>), although a bit old, provides an excellent introductory example to using Python and Hadoop streaming.</p><h2 id="case-description">(1) Case Description</h2><p>In this blog, I'm going to use a word-count example to show how to run MadReduce task by Python. The data I used in this example is twitter data (json), and the goal is to count the occurrence of a list of words. To achieve the goal, I would revise the Python code in the tutorial above.</p><h2 id="adjust-the-code-for-python-hadoop-example">(2) Adjust the Code For Python-Hadoop-Example</h2><p>The tutorial above uses mapper.py and reducer.py to run MapReduce task but these two files are in Python 2.7, which is out of date. Therefore, I would change it into Python 3.+ format and adjust it according to the case requirement.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">"""mapper.py"""</span><br><br><span class="hljs-keyword">import</span> sys <br><span class="hljs-keyword">import</span> json <br><span class="hljs-keyword">import</span> re<br>pronouns = [<span class="hljs-string">"han"</span>, <span class="hljs-string">"hon"</span>, <span class="hljs-string">"den"</span>, <span class="hljs-string">"det"</span>, <span class="hljs-string">"denna"</span>, <span class="hljs-string">"denne"</span>, <span class="hljs-string">"hen"</span>, <span class="hljs-string">"unique_tweet"</span>]<br><span class="hljs-comment"># input comes from STDIN (standard input) </span><br><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> sys.stdin:<br>    <span class="hljs-comment"># remove leading and trailing whitespace </span><br>    line = line.strip()<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(line) != <span class="hljs-number">0</span>:<br>    <span class="hljs-comment"># use json to load the tweets</span><br>        jsonData = json.loads(line)<br>        <span class="hljs-comment"># determine whether it's retweet or not if 'retweeted_status' not in jsonData:</span><br>        tweets = jsonData[<span class="hljs-string">'text'</span>]<br>        <span class="hljs-comment"># split the text into words</span><br>        pattern = re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">r"\w+"</span>)<br>        words = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">str</span>, pattern.findall(tweets))) <br>        <span class="hljs-comment"># increase counters </span><br>        words.append(<span class="hljs-string">'unique_tweet'</span>)<br>        <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:<br>            word = word.lower() <br>            <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> pronouns:<br>            <span class="hljs-comment"># write the results to STDOUT (standard output);</span><br>            <span class="hljs-comment"># what we output here will be the input for the</span><br>            <span class="hljs-comment"># Reduce step, i.e. the input for reducer.py #</span><br>            <span class="hljs-comment"># tab-delimited; the trivial word count is 1</span><br>                <span class="hljs-built_in">print</span>(word, <span class="hljs-number">1</span>)<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">"""reducer.py"""</span><br><br><span class="hljs-keyword">import</span> sys <br><span class="hljs-keyword">from</span> operator <span class="hljs-keyword">import</span> itemgetter<br><br>current_word = <span class="hljs-literal">None</span><br>current_count = <span class="hljs-number">0</span> <br>word = <span class="hljs-literal">None</span><br><span class="hljs-comment"># input comes from STDIN  </span><br><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> sys.stdin:<br>    <span class="hljs-comment"># remove leading and trailing whitespace </span><br>    line = line.strip()<br>    <span class="hljs-comment"># parse the input we got from mapper.py word, </span><br>    count = line.split(<span class="hljs-string">'\t'</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># convert count (currently a string) to int </span><br>    <span class="hljs-keyword">try</span>:<br>        count = <span class="hljs-built_in">int</span>(count) <br>    <span class="hljs-keyword">except</span> ValueError:<br>        <span class="hljs-comment"># count was not a number, so silently </span><br>        <span class="hljs-comment"># ignore/discard this line</span><br>        <span class="hljs-keyword">continue</span><br>    <span class="hljs-comment"># this IF-switch only works because Hadoop sorts map output </span><br>    <span class="hljs-comment"># by key (here: word) before it is passed to the reducer</span><br>    <span class="hljs-keyword">if</span> current_word == word:<br>        current_count += count <br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">if</span> current_word:<br>            <span class="hljs-comment"># write result to STDOUT </span><br>            <span class="hljs-built_in">print</span>(current_word, current_count)<br>        current_count = count <br>        current_word = word<br>    <span class="hljs-comment"># don't forget to output the last word if needed! </span><br>    <span class="hljs-keyword">if</span> current_word == word:<br>        <span class="hljs-built_in">print</span>(current_word, current_count)<br></code></pre></td></tr></tbody></table></figure><h2 id="run-the-code-on-hadoop">(3) Run the Code on Hadoop</h2><p>Before we actually run the task on Hadoop, it's better to have a local test about mapper.py and reducer.py on small data set to check if it's able to run successfully. The command for local test is given as below.</p><figure class="highlight gradle"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gradle"># The format is <span class="hljs-string">'cat /path-of-data-set | /path-of-mapper.py  | sort -k1,1 | /path-of-reducer.py'</span><br>cat <span class="hljs-regexp">/home/u</span>buntu<span class="hljs-regexp">/tweets/</span>tweets_0.txt | <span class="hljs-regexp">/home/u</span>buntu<span class="hljs-regexp">/python/m</span>apper.py | <span class="hljs-keyword">sort</span> -k1,<span class="hljs-number">1</span> | <span class="hljs-regexp">/home/u</span>buntu<span class="hljs-regexp">/python/</span>reducer.py<br></code></pre></td></tr></tbody></table></figure><p>If we can get the expected result on the test, then we can run the Hadoop task. First, we put the data set into HDFS, and then run these two Python file on Hadoop.</p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># The format is 'hadoop fs -put /path-of-data-set /folder-in-HDFS'</span><br>hadoop fs -put <span class="hljs-regexp">/home/u</span>buntu<span class="hljs-regexp">/test1/</span>RC_2005-<span class="hljs-number">12</span> /test1<br><br><span class="hljs-comment"># Check if the data is in HDFS</span><br>hadoop fs -ls /test1<br><br><span class="hljs-comment"># Run the Python-Hadoop task</span><br>bin<span class="hljs-regexp">/hadoop jar contrib/</span>streaming/hadoop-*streaming*.jar \<br>-file <span class="hljs-regexp">/home/u</span>buntu<span class="hljs-regexp">/python/m</span>apper.py    -mapper <span class="hljs-regexp">/home/u</span>buntu<span class="hljs-regexp">/python/m</span>apper.py \<br>-file <span class="hljs-regexp">/home/u</span>buntu<span class="hljs-regexp">/python/</span>reducer.py   -reducer <span class="hljs-regexp">/home/u</span>buntu<span class="hljs-regexp">/python/</span>reducer.py \<br>-input <span class="hljs-regexp">/test1/</span>*  -output /test1-output<br><br><span class="hljs-comment"># Check the output file</span><br>hadoop fs -cat <span class="hljs-regexp">/test1-output/</span>part-<span class="hljs-number">00000</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;While Hadoop/MapReduce is based on Java, it is not necessary to use Java to write the mapper and reducer. The Hadoop framework provides t</summary>
      
    
    
    
    <category term="Data Engineering" scheme="http://example.com/categories/Data-Engineering/"/>
    
    
    <category term="Hadoop" scheme="http://example.com/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Run Word-Count Example of Hadoop (Java Version)</title>
    <link href="http://example.com/2022/02/15/hadoop-on-cloud/"/>
    <id>http://example.com/2022/02/15/hadoop-on-cloud/</id>
    <published>2022-02-15T12:19:11.000Z</published>
    <updated>2022-04-13T09:21:29.557Z</updated>
    
    <content type="html"><![CDATA[<p>The main content of this blog is introducing how to run word count example by Hadoop and Java on the cloud, including set up the Hadoop configuration, generate and adjust the Java code for Hadoop, and commands of running Hadoop. Before this, make sure that <a href="https://imchengliang.top/2022/01/21/cloud/">Linux has been installed on your cloud service</a>, both Java and Hadoop are installed on your Linux system.</p><h2 id="word-count-example-in-local-standalone-mode">(1) Word Count Example in Local (Standalone) Mode</h2><p>The Standalone mode refers to an independent Java process that runs on a host and runs in non-distributed mode by default. It uses a local file system instead of a distributed file system and does not require any Hadoop daemons to be loaded.</p><p>The default mode for Hadoop is standalone mode, so once hadoop is installed, we just need to put to data into input folder and run the command directly.</p><p>Firstly, we create the input folder on local filesystem, and then we download the data that can be used for word-count from internet and put it into the input folder. </p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># On Ubuntu linux ‘wget’ command can be used to download data over http</span><br>wget http:<span class="hljs-regexp">//</span>www.gutenberg.org<span class="hljs-regexp">/ebooks/</span><span class="hljs-number">20417</span>.txt.utf-<span class="hljs-number">8</span><br></code></pre></td></tr></tbody></table></figure><p></p><p>After the data is ready, we can run the following command (there is only one command!) to run the canonical MapReduce example.</p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/hadoop-3.3.1/</span>bin<span class="hljs-regexp">/hadoop jar /u</span>sr<span class="hljs-regexp">/local/</span>hadoop-<span class="hljs-number">3.3</span>.<span class="hljs-number">1</span><span class="hljs-regexp">/share/</span>hadoop<span class="hljs-regexp">/mapreduce/</span>hadoop*examples*.jar wordcount <span class="hljs-regexp">/home/u</span>buntu<span class="hljs-regexp">/wordcount/i</span>nput <span class="hljs-regexp">/home/u</span>buntu<span class="hljs-regexp">/wordcount/</span>output<br></code></pre></td></tr></tbody></table></figure><ul><li>The format of this command: /installation directory of Hadoop/bin/hadoop jar /installation directory of Hadoop/share/hadoop/mapreduce/hadoop<em>examples</em>.jar wordcount /path of stored-data /path for the output</li></ul><p>Note: the folder names “input” and “output” are arbitrary - you can choose any names you like for the input and output directories. But the “input” folder should contain the downloaded file. Note that the output folder is created by Hadoop, so you should not create it manually before running the command above.</p><h2 id="word-count-example-in-pseudo-distributed-mode">(2) Word Count Example in Pseudo-Distributed Mode</h2><p>The Pseudo-distributed mode refers to running on one host, using multiple Java processes to imitate various nodes that run in fully distributed mode but not actually be used in production. The pseudo-distributed mode has the main functions of the fully distributed mode.</p><p>Firstly, we need to edit the configuration file to switch Hadoop into pseudo-distributed mode. The two configuration files that are needed to be edited are 'core-site.xml' and 'hdfs-site.xml', and they are located on '/installation directory of Hadoop/etc/hadoop'.</p><figure class="highlight dts"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-meta"># core-site.xml</span><br><span class="hljs-params">&lt;configuration&gt;</span><br>    <span class="hljs-params">&lt;property&gt;</span><br>        <span class="hljs-params">&lt;name&gt;</span>fs.defaultFS<span class="hljs-params">&lt;/name&gt;</span><br>        <span class="hljs-params">&lt;value&gt;</span>hdfs:<span class="hljs-comment">//localhost:9000&lt;/value&gt;</span><br>    <span class="hljs-params">&lt;/property&gt;</span><br><span class="hljs-params">&lt;/configuration&gt;</span><br></code></pre></td></tr></tbody></table></figure><figure class="highlight dts"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-meta"># hdfs-site.xml</span><br><span class="hljs-params">&lt;configuration&gt;</span><br>    <span class="hljs-params">&lt;property&gt;</span><br>        <span class="hljs-params">&lt;name&gt;</span>dfs.replication<span class="hljs-params">&lt;/name&gt;</span><br>        <span class="hljs-params">&lt;value&gt;</span><span class="hljs-number">1</span><span class="hljs-params">&lt;/value&gt;</span><br>    <span class="hljs-params">&lt;/property&gt;</span><br><span class="hljs-params">&lt;/configuration&gt;</span><br></code></pre></td></tr></tbody></table></figure><ul><li>We configurate the global parameters of cluster including HDFS URL and temporary directory of Hadoop by editing core-site.xml. The parameters of HDFS are stored in hdfs-site.xml, such as the storage location of the name node and data node, the number of file copies, the read permission of the file, etc.</li></ul><p>After the configuration files are ready, let's check that if we can ssh to the localhost without a passphrase.</p><figure class="highlight elixir"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs elixir"><span class="hljs-variable">$ </span>ssh localhost<br></code></pre></td></tr></tbody></table></figure><p>If we cannot ssh to localhost without a passphrase, execute the following commands to setup passphraseless ssh</p><figure class="highlight arcade"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs arcade">$ ssh-keygen -t rsa -P <span class="hljs-string">''</span> -f ~<span class="hljs-regexp">/.ssh/i</span>d_rsa<br>$ cat ~<span class="hljs-regexp">/.ssh/i</span>d_rsa.pub &gt;&gt; ~<span class="hljs-regexp">/.ssh/</span>authorized_keys<br>$ chmod <span class="hljs-number">0600</span> ~<span class="hljs-regexp">/.ssh/</span>authorized_keys<br></code></pre></td></tr></tbody></table></figure><p>The next step is to use the following commands in the installation directory of Hadoop to start a MapReduce job in pseudo-distributed mode locally. </p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># Format the filesystem</span><br>$ bin/hdfs namenode -format<br><span class="hljs-comment"># Start NameNode daemon and DataNode daemon</span><br>$ sbin/start-dfs.sh<br><span class="hljs-comment"># Make the HDFS directories required to execute MapReduce jobs</span><br>$ bin<span class="hljs-regexp">/hdfs dfs -mkdir /u</span>ser<br>$ bin<span class="hljs-regexp">/hdfs dfs -mkdir /u</span>ser/&lt;username&gt;<br></code></pre></td></tr></tbody></table></figure><p></p><p>We can check if the job starts successfully by the command 'jps'. </p><figure class="highlight vala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs vala">$ jps<br><span class="hljs-meta"># if the following namenode, datanode, secondarynamenode are all shown, it means that the job has started</span><br><span class="hljs-meta"># 6818 DataNode</span><br><span class="hljs-meta"># 6651 NameNode</span><br><span class="hljs-meta"># 7067 SecondaryNameNode</span><br><span class="hljs-meta"># 91869 Jps</span><br></code></pre></td></tr></tbody></table></figure><p></p><ul><li>DataNode stores data block, NameNode is to accept the read and write requests from client and send them to DataNode, SecondaryNameNode helps NameNode merge edits log to reduce NameNode’s startup time.</li></ul><h2 id="create-and-modify-the-java-code-for-word-count-example">(3) Create and Modify the Java code for Word Count Example</h2><p>Now we write the Java code to count the words in the txt file that is downloaded in step (1), the goal is that the output of the job should thus be a file containing lines like: a number_of_words_starting_with_a_or_A</p><p>First of all, we create and edit the Java file in any path of the local filesystem we want. </p><figure class="highlight irpf90"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs irpf90"><span class="hljs-keyword">touch</span> &lt;Java <span class="hljs-keyword">file</span> <span class="hljs-keyword">name</span>&gt;.java<br>vim &lt;Java <span class="hljs-keyword">file</span> <span class="hljs-keyword">name</span>&gt;,java<br></code></pre></td></tr></tbody></table></figure><p></p><p>The Java code is copied from the <a href="https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">official sample of Apache Hadoop</a>, and then adjust the code based on the requirement above. The two key function mapper and reducer after adjustment are shown as below, the full code can be find in <a href="https://github.com/Imchengliang/Data-Engineering">there</a> </p><figure class="highlight angelscript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-keyword">public</span> static <span class="hljs-keyword">class</span> <span class="hljs-symbol">FirstLetterCountMapper</span><br><span class="hljs-symbol">extends</span> <span class="hljs-symbol">Mapper</span>&lt;<span class="hljs-symbol">LongWritable, <span class="hljs-symbol">Text</span>, <span class="hljs-symbol">Text</span>, <span class="hljs-symbol">IntWritable</span></span>&gt; {<br>    @Override<br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> map(LongWritable key, Text value, Context context) <br>throws IOException, InterruptedException {<br># change the input data <span class="hljs-built_in">int</span>o <span class="hljs-built_in">string</span> <span class="hljs-keyword">and</span> make all the letters of it be lowercase<br>String line = value.toString().toLowerCase();<br># split the <span class="hljs-built_in">string</span> data <span class="hljs-built_in">int</span>o individual word by blankspace<br>String[] <span class="hljs-built_in">string</span>s = line. split(<span class="hljs-string">" "</span>);<br><span class="hljs-keyword">for</span>(<span class="hljs-built_in">int</span> i=<span class="hljs-number">0</span>; i&lt;<span class="hljs-built_in">string</span>s.length; i++) {<br># filter <span class="hljs-keyword">out</span> empty <span class="hljs-built_in">string</span>s<br><span class="hljs-keyword">if</span> ( <span class="hljs-built_in">string</span>s[i] != <span class="hljs-literal">null</span> &amp;&amp; !<span class="hljs-built_in">string</span>s[i].isEmpty() ){<br># extract the first letter of <span class="hljs-keyword">this</span> word<br>char firstLetter = <span class="hljs-built_in">string</span>s[i].charAt(<span class="hljs-number">0</span>);<br># find the words begin with a-z <span class="hljs-keyword">and</span> deliver their first letter to reducer <span class="hljs-keyword">class</span><br>    <span class="hljs-symbol">if</span> (<span class="hljs-symbol">firstLetter</span> &gt;= '<span class="hljs-symbol">a</span>' &amp;&amp; <span class="hljs-symbol">firstLetter</span> &lt;= '<span class="hljs-symbol">z</span>') {<br>        context.write(new Text(String.valueOf(firstLetter)), new IntWritable(<span class="hljs-number">1</span>));<br>}<br>                }<br>            }<br>}<br>    } <br><br><span class="hljs-keyword">public</span> static <span class="hljs-keyword">class</span> <span class="hljs-symbol">FirstLetterCountReducer</span><br><span class="hljs-symbol">extends</span> <span class="hljs-symbol">Reducer</span>&lt;<span class="hljs-symbol">Text, <span class="hljs-symbol">IntWritable</span>, <span class="hljs-symbol">Text</span>, <span class="hljs-symbol">IntWritable</span></span>&gt; {<br><span class="hljs-keyword">private</span> IntWritable result = new IntWritable();<br>@Override<br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context)  <br>throws IOException, InterruptedException {<br><span class="hljs-built_in">int</span> sum = <span class="hljs-number">0</span>;<br># count the number of words begin with a-z <span class="hljs-keyword">in</span> a loop<br><span class="hljs-keyword">for</span> (IntWritable val : values) {<br>sum += val.<span class="hljs-keyword">get</span>();<br>            }<br>result.<span class="hljs-keyword">set</span>(sum);<br>context.write(key, result);<br>       }<br>    }<br></code></pre></td></tr></tbody></table></figure><p></p><p>After the file edition is finished, we need to compile the wordcount example and make a jar file. </p><figure class="highlight applescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs applescript">cd /directory <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> folder <span class="hljs-keyword">that</span> <span class="hljs-keyword">contains</span> Java <span class="hljs-built_in">file</span><br>javac -cp `/installation directory <span class="hljs-keyword">of</span> Hadoop/bin/hadoop classpath` &lt;Java <span class="hljs-built_in">file</span> <span class="hljs-built_in">name</span>&gt;.java<br>jar -cvf &lt;Java <span class="hljs-built_in">file</span> <span class="hljs-built_in">name</span>&gt;.jar  *.<span class="hljs-built_in">class</span><br></code></pre></td></tr></tbody></table></figure><p></p><p>Now there is a file “<java file="" name="">.jar” in the same folder contains Java file. Next, load the file whose words we are counting into hdfs. </java></p><figure class="highlight livecodeserver"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">/installation <span class="hljs-built_in">directory</span> <span class="hljs-keyword">of</span> Hadoop/bin/hdfs dfs -<span class="hljs-built_in">put</span> /<span class="hljs-built_in">directory</span> <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> data we are going <span class="hljs-built_in">to</span> <span class="hljs-built_in">process</span><br></code></pre></td></tr></tbody></table></figure><p></p><ul><li>There should be a file in hdfs now, and we can check it by this command: /installation directory of Hadoop/bin/hdfs dfs -ls input</li></ul><p>Then, we run the following command to run the Java code in Hadoop. </p><figure class="highlight applescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs applescript">/installation directory <span class="hljs-keyword">of</span> Hadoop/bin/hadoop jar &lt;Java <span class="hljs-built_in">file</span> <span class="hljs-built_in">name</span>&gt;.jar &lt;Java <span class="hljs-built_in">file</span> <span class="hljs-built_in">name</span>&gt; input output<br></code></pre></td></tr></tbody></table></figure><p></p><p>If the hadoop run completes normally, verify that the output looks as expected. First check the content of the output directory in hdfs. Then check the content of the output file using the ‘-cat’ argument to ‘hdfs dfs’. </p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/installation directory of Hadoop/</span>bin/hdfs dfs -ls output<br><span class="hljs-regexp">/installation directory of Hadoop/</span>bin<span class="hljs-regexp">/hdfs dfs -cat output/</span>part-r-<span class="hljs-number">00000</span><br></code></pre></td></tr></tbody></table></figure><p></p><ul><li>The output files are by default named part-x-yyyyy where: x is either 'm' or 'r', depending on whether the job was a map only job, or reduce. yyyyy is the mapper or reducer task number (zero based).</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The main content of this blog is introducing how to run word count example by Hadoop and Java on the cloud, including set up the Hadoop c</summary>
      
    
    
    
    <category term="Data Engineering" scheme="http://example.com/categories/Data-Engineering/"/>
    
    
    <category term="Hadoop" scheme="http://example.com/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Show the Hidden File on Mac OS</title>
    <link href="http://example.com/2022/01/29/hidden-file/"/>
    <id>http://example.com/2022/01/29/hidden-file/</id>
    <published>2022-01-29T10:09:26.000Z</published>
    <updated>2022-04-07T11:36:03.283Z</updated>
    
    <content type="html"><![CDATA[<p>Sometimes we might need to edit the hidden file on Mac such as the configuration file but we don't know the path of this file. Therefore, letting the computer shows the hidden file allows us to locate and edit this file more convenient. This post would introduce two ways to show the hidden file on Mac.</p><h2 id="enter-the-command-of-show-hide-hidden-file">(1) Enter the command of show / hide hidden file</h2><p>We can directly enter the following commands on terminal to show or hide all the hidden files. </p><figure class="highlight applescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs applescript"><span class="hljs-comment"># Show the hidden files</span><br>defaults <span class="hljs-built_in">write</span> com.apple.finder AppleShowAllFiles -<span class="hljs-built_in">boolean</span> <span class="hljs-literal">true</span>;killall Finder<br><span class="hljs-comment"># Hide the hidden files</span><br>defaults <span class="hljs-built_in">write</span> com.apple.finder AppleShowAllFiles -<span class="hljs-built_in">boolean</span> <span class="hljs-literal">false</span>;killall Finder<br></code></pre></td></tr></tbody></table></figure><p></p><h2 id="create-the-sh-file-that-contains-the-two-commands-above-and-use-the-file-to-show-hide-the-hidden-files">(2) Create the SH file that contains the two commands above, and use the file to show / hide the hidden files</h2><p>The commands above is so long that it's hard to remember and type it correctly. Hence, we can store them in the SH file, and each time we run the SH file can also achieve the same effect. </p><figure class="highlight jboss-cli"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli"><span class="hljs-comment"># Create the SH files </span><br>touch show_hidden_file.sh<br>touch hide_hidden_file.sh<br><br><span class="hljs-comment"># Write the show_hidden_files_command into show_hidden_file.sh</span><br><span class="hljs-comment"># Write the hide_hidden_files_command into hide_hidden_file.sh</span><br><br><span class="hljs-comment"># Show the hidden files</span><br><span class="hljs-string">./show_hidden_file.sh</span><br><span class="hljs-comment"># Hide the hidden files</span><br><span class="hljs-string">./hide_hidden_file.sh</span><br></code></pre></td></tr></tbody></table></figure><p></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Sometimes we might need to edit the hidden file on Mac such as the configuration file but we don&#39;t know the path of this file. Therefore,</summary>
      
    
    
    
    <category term="Data Engineering" scheme="http://example.com/categories/Data-Engineering/"/>
    
    
    <category term="Mac" scheme="http://example.com/tags/Mac/"/>
    
  </entry>
  
  <entry>
    <title>Use SSH to connect the virtual machine on cloud and run jupyter notebook on it</title>
    <link href="http://example.com/2022/01/21/cloud/"/>
    <id>http://example.com/2022/01/21/cloud/</id>
    <published>2022-01-21T08:36:42.000Z</published>
    <updated>2022-04-07T11:35:21.523Z</updated>
    
    <content type="html"><![CDATA[<p>In this blog, I will introduce how to create a virtual machine on openstack (it's a cloud platform), and then using SSH to connect the virtual machine with local computer. After the connection, I will show how to run jupyter notebook on this remote virtual machine.</p><h2 id="create-a-ssh-keypair-on-openstack">(1) Create a SSH-keypair on openstack</h2><p>The only method allowed to access the cloud instances is via ssh-keypairs. Username/Password is disabled by default on all cloud instances (according to best practice) and should never be enabled for security reasons.</p><p>The OpenStack software helps us create/import keys, and will make sure that the public keys are injected in the instances you create. The private key should be private and is for us to safekeep on our clients.</p><p>In the OpenStack dashboard: Compute -&gt; Key Pairs -&gt; Create Key Pair</p><p>Save the downloaded .pem file in a secure location on computer. We would need it when we want to access the virtual machine instance but we don't need to create a new ssh-keypair each time. <img src="/img/ssh_vm/ssh.png"></p><h2 id="launch-an-instance-of-virtual-machine-on-openstack">(2) Launch an instance of virtual machine on openstack</h2><p>In the OpenStack dashboard: Compute -&gt; Instances -&gt; Launch instance</p><p>Then we can choose the configuration we want for the virtual machine. For my instance, I choose ubuntu 20.04 as the image, 1 VCPUS, 512 MB RAM and 20 GB disk. We also have to give this instance a name, and it would auto select to use the key-pair we create. As for the rest of the configuration, I chose the default for them. <img src="/img/ssh_vm/configuration.png"></p><h2 id="use-ssh-to-access-the-virtual-machine-from-local-computer">(3) Use SSH to access the virtual machine from local computer</h2><p>Before the SSH connection, we need to associate a floating IP to the instance, which represents the IP address of this virtual machine. After the IP setting, we should change the permission of the downloaded-keypair file and SSH file so that the IP can access the key and connect with local computer. Run the following commands in terminal to change permission. "/..." is the path of this file on your computer. </p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">chmod <span class="hljs-number">400</span> <span class="hljs-regexp">/.../</span>liang_cheng.pem<br>chmod <span class="hljs-number">700</span> <span class="hljs-regexp">/.../</span>.ssh<br>chmod <span class="hljs-number">600</span> <span class="hljs-regexp">/.../</span>.ssh/authorized_keys<br></code></pre></td></tr></tbody></table></figure><p></p><p>After the permission-change, we are able to use SSH to access the virtual machine by running the commands below.</p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># if the instance uses old volume or snapshot but not a new image as the boot source, </span><br><span class="hljs-comment"># we need to run the next command first before run ssh -i </span><br>ssh-keygen -R floating IP<br>ssh -i <span class="hljs-regexp">/.../</span>liang_cheng.pem ubuntu@floating IP<br></code></pre></td></tr></tbody></table></figure><p><img src="/img/ssh_vm/ubuntu.png"></p><h2 id="install-jupyter-notebook-and-run-it-on-the-virtual-machine">(4) Install jupyter notebook and run it on the virtual machine</h2><p>Firstly, we need to install pip and jupyter notebook on the virtual machine.</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># switch to root user first</span><br>sudo su<br>apt install python3-pip<br>pip install jupyter notebook<br><span class="hljs-comment"># if it shows error 'E: Package &lt;packagename&gt; has no installation candidate'</span><br><span class="hljs-comment"># run the following commands and then install pip and jupyter notebook</span><br>apt-<span class="hljs-builtin-name">get</span> update<br>apt-<span class="hljs-builtin-name">get</span> upgrade<br></code></pre></td></tr></tbody></table></figure><p>Then we edit the config file of jupyter notebook so that we can remotely log in it on the local browser.</p><figure class="highlight vim"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs vim">jupyter notebook --generate-config<br><span class="hljs-keyword">vim</span> /.../jupyter_notebook_config.<span class="hljs-keyword">py</span><br># after entering the <span class="hljs-keyword">file</span>, press button O <span class="hljs-keyword">to</span> <span class="hljs-built_in">get</span> into <span class="hljs-keyword">edit</span> <span class="hljs-keyword">mode</span><br># <span class="hljs-built_in">add</span> the following three codes into the config <span class="hljs-keyword">file</span><br><span class="hljs-keyword">c</span>.NotebookApp.ip=<span class="hljs-string">'*'</span><br><span class="hljs-keyword">c</span>.NotebookApp.open_browser=False<br><span class="hljs-keyword">c</span>.NotebookApp.port=<span class="hljs-number">8888</span><br># press button esc <span class="hljs-keyword">to</span> turn off <span class="hljs-keyword">edit</span> <span class="hljs-keyword">mode</span>, <span class="hljs-built_in">and</span> <span class="hljs-built_in">type</span> :wq! <span class="hljs-keyword">to</span> save the <span class="hljs-keyword">changes</span> in <span class="hljs-keyword">file</span><br></code></pre></td></tr></tbody></table></figure><p>After everything is set up, we can run jupyter notebook. </p><figure class="highlight ada"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">jupyter notebook <span class="hljs-comment">--allow-root</span><br></code></pre></td></tr></tbody></table></figure><p></p><p><img src="/img/ssh_vm/notebook.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In this blog, I will introduce how to create a virtual machine on openstack (it&#39;s a cloud platform), and then using SSH to connect the vi</summary>
      
    
    
    
    <category term="Data Engineering" scheme="http://example.com/categories/Data-Engineering/"/>
    
    
    <category term="Virtual Machine" scheme="http://example.com/tags/Virtual-Machine/"/>
    
  </entry>
  
  <entry>
    <title>Install and Control Different Version of Python on Mac</title>
    <link href="http://example.com/2022/01/16/Mac/"/>
    <id>http://example.com/2022/01/16/Mac/</id>
    <published>2022-01-16T20:21:35.000Z</published>
    <updated>2022-04-07T11:35:58.783Z</updated>
    
    <content type="html"><![CDATA[<p>The default version of Python installed on the Mac OS is 2.7, and if we intall Anaconda, the version 3.7 of Python would overwrite the version 2.7 to become the default version of Python in the computer. But now some third-party modules might require the Python version to be 3.8 at least (It's the situation I met when I try to use snscrape, a module for social media data crawler). Under this situation, we need to download and install the right version of Python. When different version of Python exist on the system, we need to arrange them properly to avoid some potential issues.</p><h2 id="download-the-installation-package-from-the-official-website-and-install-it-on-mac">(1) Download the installation package from the official website and install it on Mac</h2><p>Choose macOS 64-bit installer, and doucble click the installer file to install after it's downloaded. Pay attention to the installation path, the default path is /Library/Frameworks/Python.framework/Versions/3.8 <img src="/img/HTCPVOMAC/jieping.png"></p><h2 id="modify-environment-variables">(2) Modify environment variables</h2><p>In order to make the newly installed Python work, we have to add its installation path to environment variables. Run vim ~/.bash_profile on terminal, and then add the following two codes to bash_profile.</p><figure class="highlight elixir"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs elixir"><span class="hljs-comment"># This path is the default installation path, if you install Python to other location, switch this path to your installation path</span><br>export PATH=<span class="hljs-variable">${</span>PATH}<span class="hljs-symbol">:/Library/Frameworks/Python</span>.framework/Versions/<span class="hljs-number">3.8</span>/bin/python3<br><span class="hljs-keyword">alias</span> python=<span class="hljs-string">"/Library/Frameworks/Python.framework/Versions/3.8/bin/python3/python3.8"</span><br></code></pre></td></tr></tbody></table></figure><p>These are to repoint the python command to the newly installed version. After the editing above, run source ~/.bash_profile on terminal to make the execution command above take effect. Then we can run python -V on terminal to check if the current version matches with the newly installed version.</p><h2 id="install-pip">(3) Install pip</h2><p>If we install multiple versions of Python, we also need to install different pip for each version of Python. To install new pip, run the following commands on terminal.</p><figure class="highlight dsconfig"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs dsconfig"><span class="hljs-string">curl</span> <span class="hljs-string">https</span>://<span class="hljs-string">bootstrap</span>.<span class="hljs-string">pypa</span>.<span class="hljs-string">io</span>/<span class="hljs-built_in">get-pip.py</span> -<span class="hljs-string">o</span> <span class="hljs-built_in">get-pip.py</span><br><span class="hljs-comment"># the number after python means your Python version, you can change it to match your Python version</span><br><span class="hljs-string">python3</span>.<span class="hljs-string">8</span> <span class="hljs-built_in">get-pip.py</span><br></code></pre></td></tr></tbody></table></figure><p>Every time pip is installed, it will modify the Python version corresponding to the default pip. Then we should run the following code on terminal to check which pip is corresponding with which Python</p><figure class="highlight nginx"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-comment"># the number behind pip means the serial number of pip, if you have n pip, then run these till pipn -V</span><br><span class="hljs-attribute">pip</span> -V<br>pip2 -V<br>pip3 -V<br></code></pre></td></tr></tbody></table></figure><h2 id="manage-different-version-of-python-to-use-which-pip">(4) Manage different version of Python to use which pip</h2><p>Generally the pip would be corresponding to the Python that is set in the environment variable, if we want to make other Python to use pip, we need to adjust the pip file.</p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#!/usr/bin/python3.6</span><br><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br>import re<br>import sys<br>from pip._internal import main<br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:<br>    sys.argv[<span class="hljs-number">0</span>] = re.sub(<span class="hljs-string">r'(-script\.pyw?|\.exe)?$'</span>, <span class="hljs-string">''</span>, sys.argv[<span class="hljs-number">0</span>])<br>    sys.<span class="hljs-keyword">exit</span>(main())<br></code></pre></td></tr></tbody></table></figure><p>Here the default Python is version 3.6, we can change the first line into other Python installation path, then this pip will be used by the Python we just set. If we want to make the specific version of Python use pip2, pip3, ..., pipn, we just need to set the first line of these pip files to the installation path of the Python we want.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The default version of Python installed on the Mac OS is 2.7, and if we intall Anaconda, the version 3.7 of Python would overwrite the ve</summary>
      
    
    
    
    <category term="Data Engineering" scheme="http://example.com/categories/Data-Engineering/"/>
    
    
    <category term="Python" scheme="http://example.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Singular Value Decomposition (SVD) Part 1</title>
    <link href="http://example.com/2022/01/14/post-1/"/>
    <id>http://example.com/2022/01/14/post-1/</id>
    <published>2022-01-14T07:49:04.000Z</published>
    <updated>2022-07-08T09:06:17.953Z</updated>
    
    <content type="html"><![CDATA[<p>Singular Value Decomposition (SVD) is a complex computation in Linear Algebra, and it's widely used in recommendation system. By SVD, the input user-ratings matrix can be divided into three different matrices: user-features, features-features and item-features matrices. This post is to show the full calculation process of SVD and explain each step among it.</p><h2 id="the-format-of-svd">The format of SVD:</h2><p><span class="math display">\[M = U \Sigma V^T\]</span> M is the input m*n matrix, <span class="math inline">\(U\)</span> are the left singular vectors (m*k matrix), <span class="math inline">\(\Sigma\)</span> are the diagonal matrix (k*k matrix), <span class="math inline">\(V\)</span> are the right singular vectors (n*k matrix).</p><h2 id="step-1-transfer-m-into-a-square-matrix">Step 1: Transfer M into a square matrix</h2><p>In order to finsh SVD, we need to know the eigenvalues of the input matrix at first. But M is not always a square matrix, and it might be retangular matrix sometimes. So firstly, we need to transfer M into a square matrix by multiplying M with its transpose. <span class="math display">\[M=\left[\begin{array}{ll}1 &amp; 1 \\0 &amp; 3 \\3 &amp; 0\end{array}\right], \quad \quad M^{\top} M=\left[\begin{array}{lll}1 &amp; 0 &amp; 3 \\1 &amp; 3 &amp; 0\end{array}\right] \cdot\left[\begin{array}{ll}1 &amp; 1 \\0 &amp; 3 \\3 &amp; 0\end{array}\right]=\left[\begin{array}{ll}10 &amp; 1 \\1 &amp; 10\end{array}\right]\]</span></p><h2 id="step-2-calculate-the-eigenvalues">Step 2: Calculate the eigenvalues</h2><p>To get the eigenvalues, we need to calculate the determinant of <span class="math inline">\(M^{\top} M - \lambda I\)</span>. In the computation of this determinant, a polynomial is obtained, and the results of this polynomial are the eigenvalues. <span class="math display">\[M^{\top} M - \lambda I=\left[\begin{array}{ll}10 - \lambda &amp; 1 \\1 &amp; 10 - \lambda\end{array}\right], \quad \quad \begin{aligned}\operatorname{det}\left(M^{\top} M-\lambda I\right) &amp;=\left(10-\lambda)^{2}-1\right.\\\lambda &amp;=11 \quad or \quad 9\end{aligned}\]</span></p><p>So the eigenvalues of <span class="math inline">\(M^{\top} M\)</span> are 11 and 9.</p><h2 id="step-3-calculate-the-eigenvectors">Step 3: Calculate the eigenvectors</h2><p>After the calculation of eigenvalues, the next step is to calculate the eigenvectors for each eigenvalue. First we plug the eigenvalues sequently as the value of <span class="math inline">\(\lambda\)</span> into <span class="math inline">\(M^{\top} M - \lambda I\)</span> to get a matrix. To obtain eigenvectors, we also have the know the null space of this matrix. Therefore, we set a vector as <span class="math inline">\(A\)</span> and calculate <span class="math inline">\(A\)</span> through the equation <span class="math inline">\((M^{\top} M - \lambda I)*A=0\)</span>. After that, we convert the vector into an unit vector, and this unit vector is the eigenvector. <span class="math display">\[For \quad \lambda = 9, \quad M^{\top} M - 9I=\left[\begin{array}{ll}1 &amp; 1 \\1 &amp; 1\end{array}\right]\]</span> <span class="math display">\[\begin{gathered}\left(M^{\top} M-9 I\right) * A=\left[\begin{array}{ll}1 &amp; 1 \\1 &amp; 1\end{array}\right] \cdot\left[\begin{array}{l}a_{1} \\a_{2}\end{array}\right], \quad{\left[\begin{array}{l}a_{1} \\a_{2}\end{array}\right]=\left[\begin{array}{c}1 \\-1\end{array}\right]}\end{gathered}\]</span> <span class="math display">\[\sqrt{a_{1}{ }^{2}+a_{2}{ }^{2}}=\sqrt{2}, \quad \text { eigenvector: }\left[\begin{array}{l}a_{1} / \sqrt{2} \\a_{2} / \sqrt{2}\end{array}\right]=\left[\begin{array}{c}1 / \sqrt{2} \\-1 / \sqrt{2}\end{array}\right]\]</span> <span class="math display">\[\\\]</span> <span class="math display">\[For \quad \lambda = 10, \quad M^{\top} M - 10I=\left[\begin{array}{ll}-1 &amp;  1 \\1 &amp; -1\end{array}\right]\]</span> <span class="math display">\[\begin{gathered}\left(M^{\top} M-10 I\right) * A=\left[\begin{array}{ll}-1 &amp;  1 \\1 &amp; -1\end{array}\right] \cdot\left[\begin{array}{l}a_{1} \\a_{2}\end{array}\right], \quad{\left[\begin{array}{l}a_{1} \\a_{2}\end{array}\right]=\left[\begin{array}{c}1 \\1\end{array}\right]}\end{gathered}\]</span> <span class="math display">\[\sqrt{a_{1}{ }^{2}+a_{2}{ }^{2}}=\sqrt{2}, \quad \text { eigenvector: }\left[\begin{array}{l}a_{1} / \sqrt{2} \\a_{2} / \sqrt{2}\end{array}\right]=\left[\begin{array}{c}1 / \sqrt{2} \\1 / \sqrt{2}\end{array}\right]\]</span></p><h2 id="step-4-construct-sigma-diagonal-matrix-and-v-right-singular-vectors">Step 4: Construct <span class="math inline">\(\Sigma\)</span> (diagonal matrix) and V (right singular vectors)</h2><p>For <span class="math inline">\(\Sigma\)</span>, the diagonal elements are the square root of eigenvalues and the rest are all zero. For V, it consists of eigenvectors and each eigenvector represents one column of data in the matrix. <span class="math display">\[V=\left[\begin{array}{cc}1 / \sqrt{2} &amp; -1 / \sqrt{2} \\1 / \sqrt{2} &amp; 1 / \sqrt{2}\end{array}\right], \quad D=\left[\begin{array}{cc}\sqrt{11} &amp; 0 \\0 &amp; \sqrt{9}\end{array}\right]\]</span></p><h2 id="step-5-calculate-u-left-singular-vectors">Step 5: Calculate U (left singular vectors)</h2><p>From <span class="math inline">\(M=U \Sigma V^T\)</span>, we get <span class="math inline">\(U=MV \Sigma^T\)</span>. First we compute <span class="math inline">\(MV\)</span> and change the vectors in this matrix into unit vector. Then we compute <span class="math inline">\(MV \Sigma^T\)</span>. After this computation, we make a unit vector transformation again, and this is the result of <span class="math inline">\(U\)</span>. <span class="math display">\[MV = \left[\begin{array}{ll}1 &amp; 1 \\0 &amp; 3 \\3 &amp; 0\end{array}\right] \cdot\left[\begin{array}{l}1/\sqrt{2} &amp; -1/\sqrt{2} \\1/\sqrt{2} &amp; 1/\sqrt{2}\end{array}\right] = \left[\begin{array}{l}\frac{2}{\sqrt{2}} &amp; 0 \\\frac{3}{\sqrt{2}} &amp; \frac{3}{\sqrt{2}} \\\frac{3}{\sqrt{2}} &amp; -\frac{3}{\sqrt{2}}\end{array}\right]\]</span> <span class="math display">\[\sqrt{(\frac{2}{\sqrt{2}})^2+(\frac{3}{\sqrt{2}})^2+(\frac{3}{\sqrt{2}})^2}=\frac{\sqrt{22}}{\sqrt{2}}, \quad \sqrt{0^2+(\frac{3}{\sqrt{2}})^2+(\frac{3}{\sqrt{2}})^2}=\frac{\sqrt{18}}{\sqrt{2}}\]</span> <span class="math display">\[MV=\left[\begin{array}{l}\frac{2}{\sqrt{2}} \cdot \frac{\sqrt{2}}{\sqrt{22}} &amp; 0 \cdot \frac{\sqrt{2}}{\sqrt{18}} \\\frac{3}{\sqrt{2}} \cdot \frac{\sqrt{2}}{\sqrt{22}} &amp; \frac{3}{\sqrt{2}} \cdot \frac{\sqrt{2}}{\sqrt{18}}\\\frac{3}{\sqrt{2}} \cdot \frac{\sqrt{2}}{\sqrt{22}} &amp; -\frac{3}{\sqrt{2}} \cdot \frac{\sqrt{2}}{\sqrt{18}}\end{array}\right] = \left[\begin{array}{l}\frac{2}{\sqrt{22}} &amp; 0 \\\frac{3}{\sqrt{22}} &amp; \frac{3}{\sqrt{18}} \\\frac{3}{\sqrt{22}} &amp; -\frac{3}{\sqrt{18}}\end{array}\right]\]</span> <span class="math display">\[MVD^T = \left[\begin{array}{l}\frac{2}{\sqrt{22}} &amp; 0 \\\frac{3}{\sqrt{22}} &amp; \frac{3}{\sqrt{18}} \\\frac{3}{\sqrt{22}} &amp; -\frac{3}{\sqrt{18}}\end{array}\right] \cdot \left[\begin{array}{cc}\sqrt{11} &amp; 0 \\0 &amp; \sqrt{9}\end{array}\right] = \left[\begin{array}{l}\frac{2\sqrt{11}}{\sqrt{22}} &amp; 0 \\\frac{3\sqrt{11}}{\sqrt{22}} &amp; \frac{3\sqrt{9}}{\sqrt{18}} \\\frac{3\sqrt{11}}{\sqrt{22}} &amp; -\frac{3\sqrt{9}}{\sqrt{18}}\end{array}\right] = \left[\begin{array}{l}\frac{2}{\sqrt{2}} &amp; 0 \\\frac{3}{\sqrt{2}} &amp; \frac{3}{\sqrt{2}} \\\frac{3}{\sqrt{2}} &amp; -\frac{3}{\sqrt{2}}\end{array}\right]\]</span> <span class="math display">\[\sqrt{(\frac{2}{\sqrt{2}})^2+(\frac{3}{\sqrt{2}})^2+(\frac{3}{\sqrt{2}})^2}=\frac{\sqrt{22}}{\sqrt{2}}, \quad \sqrt{0^2+(\frac{3}{\sqrt{2}})^2+(\frac{3}{\sqrt{2}})^2}=\frac{\sqrt{18}}{\sqrt{2}}\]</span> <span class="math display">\[MV\Sigma^T = \left[\begin{array}{l}\frac{2}{\sqrt{2}} \cdot \frac{\sqrt{2}}{\sqrt{22}} &amp; 0 \cdot \frac{\sqrt{2}}{\sqrt{18}} \\\frac{3}{\sqrt{2}} \cdot \frac{\sqrt{2}}{\sqrt{22}} &amp; \frac{3}{\sqrt{2}} \cdot \frac{\sqrt{2}}{\sqrt{18}}\\\frac{3}{\sqrt{2}} \cdot \frac{\sqrt{2}}{\sqrt{22}} &amp; -\frac{3}{\sqrt{2}} \cdot \frac{\sqrt{2}}{\sqrt{18}}\end{array}\right] = \left[\begin{array}{l}\frac{2}{\sqrt{22}} &amp; 0 \\\frac{3}{\sqrt{22}} &amp; \frac{3}{\sqrt{18}} \\\frac{3}{\sqrt{22}} &amp; -\frac{3}{\sqrt{18}}\end{array}\right] = U\]</span></p><p>*The 5 steps above is the full procedure of SVD. After all <span class="math inline">\(U\)</span>, <span class="math inline">\(\Sigma\)</span>, <span class="math inline">\(V\)</span> are obtain, we should compute <span class="math inline">\(U\Sigma V^T\)</span> to check if the result is equal to <span class="math inline">\(M\)</span>. This is to verify the SVD we make is right.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Singular Value Decomposition (SVD) is a complex computation in Linear Algebra, and it&#39;s widely used in recommendation system. By SVD, the</summary>
      
    
    
    
    <category term="Mathematics" scheme="http://example.com/categories/Mathematics/"/>
    
    
    <category term="Linear Algebra" scheme="http://example.com/tags/Linear-Algebra/"/>
    
  </entry>
  
  <entry>
    <title>Vector Space</title>
    <link href="http://example.com/2021/12/23/post/"/>
    <id>http://example.com/2021/12/23/post/</id>
    <published>2021-12-23T14:15:11.000Z</published>
    <updated>2022-04-07T11:10:59.484Z</updated>
    
    <content type="html"><![CDATA[<p>In mathematics, vector space is a set of objects that can be operated(added, multipled and so on) together with number</p><h2 id="a-vector-space-is-a-triplev-.-and-it-must-obey-the-following-9-rules">A vector space is a triple(V, +, .) and it must obey the following 9 rules:</h2><ol type="1"><li>Closure by addition: <span class="math display">\[ \forall u, w \in V, \quad u+w \in V \]</span></li><li>Additive associality: <span class="math display">\[ \forall u, v, w \in V, \quad (u+v)+w=u+(v+w) \]</span></li><li>Additive commutativity: <span class="math display">\[ \forall u, w \in V, \quad u+w = w+u \]</span></li><li>Additive identity: <span class="math display">\[ \exists 0 \in V, \quad u+0 = 0+u \]</span></li><li>Additive inverse: <span class="math display">\[ \forall u \in V, \quad -u \in V \quad s.t. \quad (-u)+u=u+(-u)=0 \]</span></li><li>Closure by scalar multiplication: <span class="math display">\[ \forall k \in R \quad and \quad u \in V, \quad k*u \in V \]</span></li><li>Multiplicative associality: <span class="math display">\[ \forall k,l \in R \quad and \quad u \in V, \quad (k*l)*u=k*(l*u)  \]</span></li><li>Multiplicative identity: <span class="math display">\[ \exists 1 \in V, \quad 1*u=u\]</span></li><li>Distributive property: <span class="math display">\[  \forall k \in R \quad and \quad u,w \in V, \quad k*(u+w)=k*u+k*w \]</span> <span class="math display">\[ \forall k,l \in R \quad and \quad u \in V, \quad (k+l)*u=k*u+l*u \]</span> *notice: the two operation in a triple is not necessary to be add and multiply</li></ol><h2 id="example">Example:</h2><p>Let $ V=R_{&gt;0} $ be the set of strictly positive real numbers. Let <span class="math inline">\(u \boxplus v = u*v\)</span> for all <span class="math inline">\(u,v \in V\)</span> and <span class="math inline">\(k \odot u=u^k\)</span> for all <span class="math inline">\(u \in V\)</span> and <span class="math inline">\(k \in R\)</span>. Show that <span class="math inline">\((V, \boxplus, \odot)\)</span> is a vector space.</p><p>Let <span class="math inline">\(u,v \in V\)</span>, then <span class="math inline">\(u \boxplus v = u*v\)</span> <br> <span class="math inline">\(\because u\)</span> and <span class="math inline">\(v\)</span> both are positive real number <br> <span class="math inline">\(\therefore u * v\)</span> is also a positive real number, so V is closure under <span class="math inline">\(\boxplus\)</span>.</p><p>Let <span class="math inline">\(v,1 \in V\)</span>, then <span class="math inline">\(v \boxplus 1 = v*1 = v\)</span> <br> <span class="math inline">\(\therefore\)</span> V has <span class="math inline">\(\boxplus\)</span> identity.</p><p>Let <span class="math inline">\(v \in V\)</span> and its <span class="math inline">\(\boxplus\)</span> identity <span class="math inline">\(=1\)</span>, then <span class="math inline">\(v \boxplus (1/v)=v*(1/v)=1\)</span>, <br> <span class="math inline">\(\therefore\)</span> V has <span class="math inline">\(\boxplus\)</span> inverse.</p><p>Let <span class="math inline">\(u,v,x \in V\)</span>, then <span class="math inline">\(u \boxplus (v \boxplus x)=u \boxplus (v*x)=u*v*x=(u \boxplus v)*x=(u \boxplus v) \boxplus x\)</span> <br> <span class="math inline">\(\therefore\)</span> V has <span class="math inline">\(\boxplus\)</span> associality.</p><p>Let <span class="math inline">\(u,v \in V\)</span>, then <span class="math inline">\(u \boxplus v=u*v=v*u=v \boxplus u\)</span> <br> <span class="math inline">\(\therefore\)</span> V has <span class="math inline">\(\boxplus\)</span> commutativity.</p><p>Let <span class="math inline">\(v \in V\)</span>, <span class="math inline">\(k \in R\)</span>, then <span class="math inline">\(k \odot v = v^k\)</span> <br> <span class="math inline">\(\because v\)</span> is a positive real number and <span class="math inline">\(k\)</span> is a real number <br> <span class="math inline">\(\therefore\)</span> $v^k $ is also a positive real number, so V is closure under <span class="math inline">\(\odot\)</span>.</p><p>Let <span class="math inline">\(v \in V\)</span>, then <span class="math inline">\(1 \odot v=v^1=v\)</span> <br> <span class="math inline">\(\therefore\)</span> V has <span class="math inline">\(\odot\)</span> identity.</p><p>Let <span class="math inline">\(v \in V\)</span> and <span class="math inline">\(a,b \in R\)</span>, then <span class="math inline">\((b \odot a) \odot v=(v^a)^b=b \odot v^a=b \odot (a \odot v)\)</span> <br> <span class="math inline">\(\therefore\)</span> V has <span class="math inline">\(\odot\)</span> associality.</p><p>Let <span class="math inline">\(u,v \in V\)</span> and <span class="math inline">\(a,b \in R\)</span>, <br> then <span class="math inline">\(a \odot (u \boxplus v)=a \odot (u*v)=(u*v)^a=u^a * v^a=(a \odot u) \boxplus (a \odot v)\)</span> <br> and <span class="math inline">\((a \boxplus b) \odot u=(a*b) \odot u=u^{a*b}=u^a * u^b=(a \odot u) \boxplus (b \odot u)\)</span> <br> <span class="math inline">\(\therefore\)</span> V has distributive property.</p><p>Therefore V fits all 9 rules and it's a vector space.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In mathematics, vector space is a set of objects that can be operated(added, multipled and so on) together with number&lt;/p&gt;
&lt;h2 id=&quot;a-vect</summary>
      
    
    
    
    <category term="Mathematics" scheme="http://example.com/categories/Mathematics/"/>
    
    
    <category term="Linear Algebra" scheme="http://example.com/tags/Linear-Algebra/"/>
    
  </entry>
  
</feed>
